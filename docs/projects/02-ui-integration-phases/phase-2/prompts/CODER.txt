===== PHASE 2: CODER PROMPT =====
ROLE: Senior TypeScript developer implementing phases of the Cody CLI integration project. You write clean, tested code following TDD principles with mocked-service tests at library boundaries.


---

PRODUCT:

**Cody** is a command-line interface for the Codex TypeScript library. It provides multi-provider LLM agent capabilities supporting OpenAI (Responses, Chat) and Anthropic (Messages) APIs with tool execution, conversation persistence, and structured tool calling. Built as a TypeScript port of OpenAI's Rust-based Codex CLI, Cody serves as both a standalone CLI tool and reference implementation for the @openai/codex-core library.


---

PROJECT CONTEXT:

# Project 02: UI Integration & Library Definition

## What We're Building

Project 02 integrates all ported Codex modules (Phases 1-6) into a working command-line interface called **Cody** and defines the library API surface for @openai/codex-core. This project validates the Rust ‚Üí TypeScript port by wiring protocol, configuration, persistence, execution, client, tools, and orchestration layers into complete conversation flows.

## Why It Matters

The port is functionally complete but untested as an integrated system. Individual modules have unit tests, but we haven't verified end-to-end workflows. This project proves the port works, exposes integration issues, and establishes the library interface that external developers will use.

## Project Success Criteria

By project completion:
- User can create conversations, send messages, receive responses (all providers: OpenAI Responses/Chat, Anthropic Messages)
- All auth methods work (API keys, ChatGPT OAuth, Claude OAuth)
- Tools execute with approval flow
- Conversations persist and resume (JSONL format)
- MCP integration functional
- Library API documented (public exports, usage examples)
- REST API designed (optional implementation)
- Zero-error quality baseline maintained (0 TS errors, 0 ESLint errors, all tests passing)

## Dependencies

- Phase 6 complete (75 modules ported, 1,876 tests passing)
- Phase 5.2 complete (quality baseline clean)
- API keys: OpenAI, Anthropic, OpenRouter
- OAuth tokens: Read from ~/.codex (ChatGPT), ~/.claude (Claude)

## Scope

**In scope:** CLI commands, provider integration (3 APIs), auth methods (4 total), tool execution, persistence/resume, library API docs, REST API spec

**Non-scope:** Script harness (Project 03), memory innovations (Projects 04-06), rich TUI, additional tools, performance optimization, production hardening


---

PHASE 2 TECHNICAL DESIGN:

# Phase 2: Technical Design

**Phase:** Tool Integration
**Goal:** Add tool execution, approval flow, and tool result handling to conversation loop

---

## Integration Overview

(From TECH-APPROACH Section 3)

Phase 2 adds tool execution to the conversation flow. Models can now request tools (exec, readFile, applyPatch, etc.), CLI prompts user for approval, tools execute, results return to model. This activates the ToolRouter and approval system from the port for the first time. The conversation loop from Phase 1 remains unchanged‚Äîwe're adding a branch point where Session detects tool calls and routes to ToolRouter instead of just returning to CLI.

---

## Actual Signatures (from ported code)

### ToolRegistry

Location: `codex-ts/src/tools/registry.ts`

```typescript
interface ToolMetadata {
  name: string;
  description: string;
  requiresApproval: boolean;
  schema?: Record<string, unknown>;
}

interface RegisteredTool<TParams = unknown, TResult = unknown> {
  metadata: ToolMetadata;
  execute: ToolFunction<TParams, TResult>;
}

class ToolRegistry {
  get(name: string): RegisteredTool | undefined
  has(name: string): boolean
  getToolNames(): string[]
}

// Global instance
export const toolRegistry = new ToolRegistry();
```

### Tool Handler Pattern

```typescript
// Each tool handler signature
type ToolFunction<TParams, TResult> = (
  params: TParams,
  options?: ToolOptions
) => Promise<TResult>;

// Example: exec tool
import {processExecToolCall, type ExecParams} from '../core/exec';

await processExecToolCall(
  {command: ['npm', 'test'], cwd: process.cwd()},
  {sandboxPolicy: 'none'}
);
```

### FunctionCall Types

Location: `codex-ts/src/protocol/items.ts`

```typescript
// Model requests tool
interface FunctionCall {
  type: 'function_call';
  id: string;
  name: string;
  arguments: string; // JSON stringified
}

// Tool returns result
interface FunctionCallOutput {
  type: 'function_call_output';
  call_id: string;
  output: string;
}
```

### Approval Callback Signature

```typescript
// CLI provides this function to Session/ToolRouter
type ApprovalCallback = (
  toolName: string,
  args: unknown
) => Promise<boolean>;

// Usage in ToolRouter
if (tool.metadata.requiresApproval) {
  const approved = await approvalCallback(toolName, params);
  if (!approved) {
    return {
      type: 'function_call_output',
      call_id: functionCall.id,
      output: JSON.stringify({error: 'User denied approval'})
    };
  }
}
```

---

## CLI Approval Implementation

### readline for Approval Prompts

```typescript
// src/cli/approval.ts
import * as readline from 'readline/promises';

export async function promptApproval(
  toolName: string,
  args: unknown
): Promise<boolean> {
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  });

  console.log(`\nTool call: ${toolName}`);
  console.log(`Arguments: ${JSON.stringify(args, null, 2)}`);

  const answer = await rl.question('Approve? (y/n): ');
  rl.close();

  return answer.toLowerCase() === 'y';
}
```

### Display Tool Execution

```typescript
// src/cli/display.ts (add to existing file)

export function renderToolCall(call: FunctionCall) {
  console.log(`\nüîß Tool: ${call.name}`);
  const args = JSON.parse(call.arguments);
  console.log(`   Args: ${JSON.stringify(args, null, 2)}`);
}

export function renderToolResult(output: FunctionCallOutput) {
  const result = JSON.parse(output.output);
  console.log(`‚úì Result: ${result.stdout || result.content || JSON.stringify(result)}\n`);
}
```

---

## Tool Detection and Routing

**How Session detects tool calls:**

```typescript
// Pseudocode from Session (check actual implementation in codex-ts/src/core/codex/session.ts)

async processMessage(message: string): Promise<ResponseItem[]> {
  // Send to ModelClient
  const items = await this.client.sendMessage(request);

  // Scan for FunctionCall items
  const toolCalls = items.filter(item => item.type === 'function_call');

  if (toolCalls.length > 0) {
    // Route to tools
    const outputs = await this.executeTools(toolCalls);
    items.push(...outputs);
  }

  return items;
}

async executeTools(calls: FunctionCall[]): Promise<FunctionCallOutput[]> {
  const outputs = [];
  for (const call of calls) {
    const tool = toolRegistry.get(call.name);
    if (!tool) {
      outputs.push({
        type: 'function_call_output',
        call_id: call.id,
        output: JSON.stringify({error: `Tool ${call.name} not found`})
      });
      continue;
    }

    // Check approval
    if (tool.metadata.requiresApproval && this.approvalCallback) {
      const args = JSON.parse(call.arguments);
      const approved = await this.approvalCallback(call.name, args);
      if (!approved) {
        outputs.push({
          type: 'function_call_output',
          call_id: call.id,
          output: JSON.stringify({error: 'User denied approval'})
        });
        continue;
      }
    }

    // Execute
    const args = JSON.parse(call.arguments);
    const result = await tool.execute(args);
    outputs.push({
      type: 'function_call_output',
      call_id: call.id,
      output: JSON.stringify(result)
    });
  }
  return outputs;
}
```

**CLI provides approval callback during Session initialization.**

---

## Mock Implementation Guide

### Mock Tool Handler

```typescript
// tests/mocks/tool-handlers.ts

export function createMockToolHandler(result: any) {
  return {
    metadata: {
      name: 'exec',
      description: 'Execute command',
      requiresApproval: true
    },
    execute: vi.fn().mockResolvedValue(result)
  };
}

// Usage
const mockExec = createMockToolHandler({
  exitCode: 0,
  stdout: 'Tests passed',
  stderr: ''
});

// Inject into registry or pass to ToolRouter
```

### Mock ModelClient with FunctionCall

```typescript
// tests/mocks/model-client.ts (enhance from Phase 1)

export function createMockClientWithToolCall(
  toolName: string,
  args: unknown
): MockModelClient {
  return {
    async sendMessage(request) {
      return [
        {
          type: 'message',
          role: 'assistant',
          content: [{type: 'text', text: 'I will execute a tool'}]
        },
        {
          type: 'function_call',
          id: 'call_123',
          name: toolName,
          arguments: JSON.stringify(args)
        }
      ];
    },
    // ... other methods
  };
}

// Usage
const mockClient = createMockClientWithToolCall('exec', {
  command: ['npm', 'test']
});
```

### Mock Approval Callback

```typescript
// In test setup
let approvalResults: boolean[] = [true, false, true]; // Pre-program responses

const mockApprovalCallback = async (toolName, args) => {
  return approvalResults.shift() ?? false;
};

// Inject into Session or wherever approval callback is used
```

---

## Wiring Approval Callback

### Where to Inject

**Session needs approval callback during construction:**

```typescript
// Check actual Session constructor in codex-ts/src/core/codex/session.ts
// Likely something like:

class Session {
  constructor(config, approvalCallback?: ApprovalCallback) {
    this.approvalCallback = approvalCallback;
  }
}
```

**CLI provides callback when creating Session/Codex:**

```typescript
// src/cli/index.ts (modify from Phase 1)
import {promptApproval} from './approval';

// When creating ConversationManager or Codex
const codex = await Codex.spawn(config, authManager, null, sessionSource, {
  approvalCallback: promptApproval  // CLI's approval function
});
```

**Exact wiring depends on actual Codex.spawn signature.** Check ported code. If unclear, try injection points and document decision.

---

## Error Handling

### Tool-Specific Errors

**ToolNotFoundError:**
- Tool name in FunctionCall not in registry
- Return FunctionCallOutput with error

**ApprovalDeniedError:**
- User says 'n' to approval prompt
- Return FunctionCallOutput with "User denied approval"

**ToolExecutionError:**
- Tool execute() throws (command fails, file not found, etc.)
- Catch error, return FunctionCallOutput with error message

**Handling in CLI:**

```typescript
try {
  await conversation.submit(input);
  const event = await conversation.nextEvent();

  // Handle events (including tool calls)
  while (event.msg.type !== 'response_complete') {
    if (event.msg.type === 'tool_call') {
      // Already handled by Session, just display
      renderToolCall(event.msg);
    } else if (event.msg.type === 'tool_result') {
      renderToolResult(event.msg);
    }

    event = await conversation.nextEvent();
  }
} catch (err) {
  console.error('Error:', err.message);
}
```

---

## Tool Execution Flow

### Complete Cycle

```typescript
// High-level flow (check actual implementation)

1. User: cody chat "run tests"
2. CLI: conversation.submit([{type: 'text', text: "run tests"}])
3. Session: Forward to ModelClient
4. ModelClient: Returns ResponseItems including FunctionCall
5. Session: Detect FunctionCall item
6. Session: Look up tool in registry
7. Session: Check requiresApproval ‚Üí call CLI's approvalCallback
8. CLI: Display prompt, wait for user input, return boolean
9. Session: If approved, execute tool.execute()
10. Tool: Execute command, return result
11. Session: Wrap result in FunctionCallOutput
12. Session: Send FunctionCallOutput back to model
13. Model: See result, respond
14. Session: Return final response
15. CLI: Display to user
```

---

## Reference Code Locations

**Tool system:**
- ToolRegistry: `codex-ts/src/tools/registry.ts`
- Tool handlers: `codex-ts/src/tools/*/index.ts` (apply-patch, read-file, etc.)
- exec tool: `codex-ts/src/core/exec/index.ts`

**Protocol types:**
- FunctionCall, FunctionCallOutput: `codex-ts/src/protocol/items.ts`
- ToolOptions: `codex-ts/src/tools/types.ts`

**Session (where tools are routed):**
- Session class: `codex-ts/src/core/codex/session.ts`
- Look for tool detection/routing logic

**If stuck:** Read these files for actual implementation patterns.

---

## Key Implementation Notes

**1. Approval callback injection point:**
Check Codex.spawn() or Session constructor for where to pass approval callback. If not obvious, may need to add parameter. Document in DECISIONS.md.

**2. Tool execution is synchronous in conversation loop:**
Model requests tool ‚Üí we execute ‚Üí return result ‚Üí model responds. Not parallel (Phase 1 constraint). Structured tool calling pattern.

**3. Display timing:**
Show tool call immediately when detected, show result when execution completes, show final model response after. User sees progress, not just final output.

**4. Error cases matter:**
User denial is normal flow (not error). Tool execution failure should be graceful (return error to model, don't crash CLI).

**5. Testing focus:**
Test approval flow (approved vs denied), test tool routing (correct tool called), test result handling (model receives output). Don't test individual tool logic (assume tools work from Phase 3 port).

---

## Integration with Phase 1 Code

**Changes to existing Phase 1 code:**

**src/cli/index.ts:**
- Import approval module
- Pass approval callback during ConversationManager/Codex creation

**src/cli/display.ts:**
- Add renderToolCall() and renderToolResult() functions
- Modify renderEvent() to handle tool-related events

**src/cli/commands/chat.ts:**
- Event loop for handling multiple events (tool calls, results, final response)
- Display each event type appropriately

**No changes to ConversationManager or Codex** - approval callback added via constructor, core logic unchanged.

---

## Testing Strategy

**Test the approval flow and tool integration, not the tools themselves.**

**What to test:**
- Approval callback gets called when tool requires approval
- Approved tools execute
- Denied tools don't execute, return denial error
- Tool results flow back to model
- CLI displays tool calls and results

**What NOT to test:**
- Does exec actually run commands? (Assume yes, Phase 3 tested exec tool)
- Does readFile actually read files? (Assume yes, Phase 4.5 tested readFile)
- Tool implementation details (not integration concern)

**Mock both ModelClient (returns FunctionCall) and tool handlers (return preset results).** Test the wiring between them.


---

TEST CONDITIONS:

# Phase 2: Test Conditions

**Test Framework:** Vitest
**Test Location:** `tests/mocked-service/phase-2-tool-execution.test.ts`
**Mocks:** model-client.ts (enhanced), tool-handlers.ts (new)

---

## Test Suite: Phase 2 Tool Execution

### Test 1: Executes Approved Tool

**Functional description:**
When model requests tool and user approves, tool executes and result returns to model.

**Setup:**
- Mock ModelClient returns FunctionCall for 'exec' tool
- Mock tool handler (exec) returns preset result
- Mock approval callback returns true (approved)

**Execute:**
- Create conversation
- Send message
- Approval callback will be called
- Tool executes

**Verify:**
- Mock tool handler execute() was called
- Response includes FunctionCallOutput item
- Output contains tool result

**Implementation:** Setup mocks with pre-programmed approval (true), verify tool.execute called, assert FunctionCallOutput in response.

---

### Test 2: Blocks Denied Tool

**Functional description:**
When model requests tool requiring approval and user denies, tool doesn't execute and denial error returned.

**Setup:**
- Mock ModelClient returns FunctionCall
- Mock tool handler (exec)
- Mock approval callback returns false (denied)

**Execute:**
- Create conversation
- Send message
- Approval callback called, returns false

**Verify:**
- Mock tool handler execute() NOT called
- Response includes FunctionCallOutput with error
- Error message contains "denied" or "User denied approval"

**Implementation:** Pre-program approval to false, verify execute not called, assert error in output.

---

### Test 3: Multiple Tools in Sequence

**Functional description:**
Model can request multiple tools in one conversation (tool A, then tool B after seeing A's result).

**Setup:**
- Mock ModelClient with two responses:
  - First: Returns FunctionCall for 'readFile'
  - Second: Returns FunctionCall for 'exec' (after seeing readFile result)
- Mock both tool handlers
- Approval callback returns true for both

**Execute:**
- Send message
- First tool executes
- Model sees result
- Second tool requested
- Second tool executes

**Verify:**
- Both tools executed (both mock handlers called)
- Both results returned
- Model received both FunctionCallOutput items

**Implementation:** Mock client with sequential responses, both approvals true, verify both handlers called in sequence.

---

### Test 4: Tool Not Found Error

**Functional description:**
If model requests tool that doesn't exist in registry, graceful error returned (doesn't crash).

**Setup:**
- Mock ModelClient returns FunctionCall for 'nonexistent_tool'

**Execute:**
- Send message
- Tool lookup fails

**Verify:**
- Response includes FunctionCallOutput with error
- Error indicates tool not found
- No crash, graceful handling

**Implementation:** Mock requests fake tool, assert error output, no throw.

---

### Test 5: Tool Execution Failure

**Functional description:**
If tool executes but fails (e.g., command returns non-zero exit code), failure communicated to model.

**Setup:**
- Mock ModelClient returns FunctionCall for 'exec'
- Mock tool handler throws or returns failure result
- Approval callback returns true

**Execute:**
- Tool approved
- Tool execution fails

**Verify:**
- FunctionCallOutput contains error or failure status
- Error message descriptive
- Model receives failure info

**Implementation:** Mock tool.execute to throw or return {exitCode: 1}, assert error in output.

---

### Test 6: Display Functions Called

**Functional description:**
CLI displays tool calls and results to user (not just silent execution).

**Setup:**
- Spy on console.log or renderToolCall/renderToolResult functions
- Mock tool execution

**Execute:**
- Tool requested and executed

**Verify:**
- renderToolCall was called (tool call displayed)
- renderToolResult was called (result displayed)
- User sees what's happening

**Implementation:** Use vi.spyOn to track display calls, assert they occurred.

---

## Mock Strategy

**Mock:**
- ModelClient (returns FunctionCall items)
- Tool handlers (return preset results, don't actually execute)
- Approval callback (pre-program yes/no responses)

**Don't mock:**
- ToolRegistry (use real registry with mocked handlers)
- Session tool routing logic (testing this integration)

**Test boundary:** Tool detection ‚Üí approval ‚Üí execution ‚Üí result flow. Assume ported tools work.

---

## Success Criteria

All 6 tests pass. Tool approval flow verified (both approval and denial). Tool execution integrated. Error cases handled. Display functions work.


---

TASKS (update source/checklist.md as you work):

# Phase 2: Tool Integration - Task Checklist

**Phase:** 2 - Tool Integration
**Status:** Not Started
**Estimated Code:** ~300 lines (CLI ~200, tests ~100)

---

## Setup

- [ ] Review Phase 1 code (understand existing CLI structure)
- [ ] Read tool registry: codex-ts/src/tools/registry.ts
- [ ] Read exec tool: codex-ts/src/core/exec/index.ts
- [ ] Understand FunctionCall/FunctionCallOutput types

---

## Approval Module

- [ ] Create src/cli/approval.ts
- [ ] Import readline/promises
- [ ] Implement promptApproval(toolName, args) function
  - [ ] Display tool name and arguments
  - [ ] Prompt user for y/n
  - [ ] Return boolean Promise
- [ ] Handle edge cases (Ctrl+C, invalid input)
- [ ] Test manually: Can prompt and get response

---

## Display Enhancements

- [ ] Open src/cli/display.ts (from Phase 1)
- [ ] Add renderToolCall(call: FunctionCall)
  - [ ] Display tool name
  - [ ] Display arguments (formatted JSON)
- [ ] Add renderToolResult(output: FunctionCallOutput)
  - [ ] Parse output JSON
  - [ ] Display result (stdout, content, or full object)
- [ ] Test: Functions render nicely to console

---

## Event Loop Enhancement

- [ ] Open src/cli/commands/chat.ts (from Phase 1)
- [ ] Modify to handle multiple events (not just single response)
- [ ] Add event loop:
  - [ ] While not complete, call nextEvent()
  - [ ] Handle different event types
  - [ ] Display appropriately
- [ ] Handle tool_call events (display via renderToolCall)
- [ ] Handle tool_result events (display via renderToolResult)
- [ ] Handle final assistant message
- [ ] Test: Event loop works for multi-event responses

---

## Approval Callback Injection

- [ ] Determine where to inject approval callback
  - [ ] Check Codex.spawn() signature
  - [ ] Or Session constructor
  - [ ] Or ConversationManager
- [ ] Modify CLI initialization (src/cli/index.ts)
  - [ ] Import promptApproval
  - [ ] Pass to Codex/Session/Manager during creation
- [ ] Document injection point in DECISIONS.md
- [ ] Test: Approval callback gets called

---

## Session Integration (if needed)

- [ ] Check if Session already routes tools (likely yes from port)
- [ ] If not: Add tool detection logic
  - [ ] Scan ResponseItems for FunctionCall
  - [ ] Look up in ToolRegistry
  - [ ] Check requiresApproval
  - [ ] Call approval callback if needed
  - [ ] Execute tool
  - [ ] Return FunctionCallOutput
- [ ] If yes: Just wire approval callback, rest works
- [ ] Document findings in DECISIONS.md

---

## Mocked-Service Tests (TDD - Write These FIRST)

### Test Setup

- [ ] Create tests/mocked-service/phase-2-tool-execution.test.ts
- [ ] Create tests/mocks/tool-handlers.ts
- [ ] Implement createMockToolHandler(result)
  - [ ] Returns RegisteredTool with mocked execute
  - [ ] Configurable result
- [ ] Enhance tests/mocks/model-client.ts
  - [ ] Add createMockClientWithToolCall(toolName, args)
  - [ ] Returns ResponseItems including FunctionCall

### Test 1: Execute Approved Tool

- [ ] Setup: Mock client with FunctionCall, mock tool handler, approval = true
- [ ] Execute: Create conversation, send message
- [ ] Verify: Tool handler execute() called
- [ ] Verify: Response includes FunctionCallOutput
- [ ] Test passes

### Test 2: Block Denied Tool

- [ ] Setup: Mock client with FunctionCall, approval = false
- [ ] Execute: Send message
- [ ] Verify: Tool handler execute() NOT called
- [ ] Verify: FunctionCallOutput has denial error
- [ ] Test passes

### Test 3: Multiple Tools Sequence

- [ ] Setup: Mock client with two tool calls
- [ ] Approval = true for both
- [ ] Execute: Send message
- [ ] Verify: Both tools executed
- [ ] Verify: Both outputs returned
- [ ] Test passes

### Test 4: Tool Not Found

- [ ] Setup: Mock client requests 'fake_tool'
- [ ] Execute: Send message
- [ ] Verify: Error output (tool not found)
- [ ] Verify: No crash
- [ ] Test passes

### Test 5: Tool Execution Fails

- [ ] Setup: Mock tool throws error
- [ ] Execute: Send message (approve)
- [ ] Verify: Error captured in output
- [ ] Verify: Model receives error message
- [ ] Test passes

### Test 6: Display Functions

- [ ] Spy on renderToolCall and renderToolResult
- [ ] Execute tool flow
- [ ] Verify: Display functions called
- [ ] Test passes

### All Tests

- [ ] All 6 tests pass
- [ ] Tests run fast (<2 seconds)
- [ ] No real tool execution (all mocked)

---

## Functional Verification (Manual CLI Testing)

- [ ] Test: Tool approval (approve case) - readFile
- [ ] Test: Tool approval (deny case) - exec
- [ ] Test: Multiple tools in conversation
- [ ] Test: Tool execution error handling
- [ ] Verify: All manual tests from manual-test-script.md pass

---

## Quality Gates

- [ ] Run: npm run format ‚Üí no changes
- [ ] Run: npm run lint ‚Üí 0 errors
- [ ] Run: npx tsc --noEmit ‚Üí 0 errors
- [ ] Run: npm test
  - [ ] Phase 2 mocked-service tests: all passing
  - [ ] Unit test baseline: 1,876+ maintained
  - [ ] No skipped tests
- [ ] Combined: npm run format && npm run lint && npx tsc --noEmit && npm test
  - [ ] All pass in sequence

---

## Documentation

- [ ] Update DECISIONS.md
  - [ ] Approval callback injection point
  - [ ] Event loop approach
  - [ ] Tool display format choices
  - [ ] Any other key decisions
- [ ] Review: All tasks checked off above
- [ ] Verify: Checklist complete

---

## Final

- [ ] All tasks complete
- [ ] All quality gates passed
- [ ] Manual testing successful
- [ ] Code committed and pushed
- [ ] Phase 2 ready for verification stages


---

STANDARDS:

See docs/core/dev-standards.md for complete coding standards.
See docs/core/contract-testing-tdd-philosophy.md for testing approach.

Key requirements:
- TypeScript strict mode, no any types
- ESLint 0 errors
- Prettier formatted
- Mocked-service tests at library boundaries
- Mock all external dependencies


---

EXECUTION WORKFLOW:

EXECUTION WORKFLOW:

1. Read all reference documents (project context, phase design, standards, test conditions)
2. Review checklist (understand all tasks)
3. Write mocked-service tests FIRST (TDD):
   - Create test file based on test-conditions.md
   - Implement mocks (ModelClient, Config, etc.)
   - Write tests for each functional condition
   - Run tests (should fail - nothing implemented)
4. Implement code to pass tests:
   - Create files listed in checklist
   - Follow design.md implementation specifics
   - Run tests after each component
   - Iterate until all tests green
5. Manual functional testing:
   - Follow manual-test-script.md
   - Execute each test case
   - Verify expected behavior
   - Document any issues
6. Quality verification:
   - Run: npm run format (fix formatting)
   - Run: npm run lint (fix errors)
   - Run: npx tsc --noEmit (fix type errors)
   - Run: npm test (verify all pass)
   - Run combined: npm run format && npm run lint && npx tsc --noEmit && npm test
   - All must pass before proceeding
7. Update artifacts:
   - Update checklist.md (check off completed tasks)
   - Update decisions.md (log implementation choices with rationale)
8. Final verification:
   - All checklist items checked
   - All quality gates pass
   - Manual tests successful
   - Decisions documented
9. Commit and push
10. Report completion, ready for quality verifier and code reviewer

DO NOT declare phase complete until all steps verified.


---

MANUAL VERIFICATION:

# Phase 2: Manual Test Script

**Purpose:** Verify tool execution and approval flow through actual CLI usage
**Prerequisites:** Phase 2 code complete, Phase 1 working, all automated tests passing
**Duration:** ~5-10 minutes

---

## Setup

1. Ensure Phase 1 works (can create conversation and chat)

2. Have test file ready:
   ```bash
   echo "test content" > /tmp/test-file.txt
   ```

3. CLI built and available:
   ```bash
   cd codex-ts
   npm run build
   cody new  # Create conversation for testing
   ```

---

## Test 1: Tool Approval - Approve Case

**Execute:**
```bash
cody chat "Read the file at /tmp/test-file.txt"
```

**Expected interaction:**
```
üîß Tool: readFile
   Args: {"filePath": "/tmp/test-file.txt"}
Approve? (y/n): y

‚úì Result: test content
Assistant: Here is the content of the file...

**Verify:**
- ‚úÖ Tool call displayed (tool name, args shown)
- ‚úÖ Approval prompt appeared
- ‚úÖ User entered 'y'
- ‚úÖ Tool executed (file content shown)
- ‚úÖ Model responded (may summarize file or acknowledge)

**If fails:** Check approval.ts exists. Verify ToolRegistry has tools. Check tool handlers wired.

---

## Test 2: Tool Approval - Deny Case

**Execute:**
```bash
cody chat "Run npm test in this directory"
```

**Expected interaction:**
```
üîß Tool: exec
   Args: {"command": ["npm", "test"]}
Approve? (y/n): n

‚ùå Tool execution denied

Assistant: I understand you don't want me to run that command.
```

**Verify:**
- ‚úÖ Tool call displayed
- ‚úÖ Approval prompt appeared
- ‚úÖ User entered 'n'
- ‚úÖ Tool did NOT execute
- ‚úÖ Denial message shown
- ‚úÖ Model received denial, responded gracefully

---

## Test 3: Multiple Tools in One Conversation

**Execute:**
```bash
cody chat "Read /tmp/test-file.txt then tell me what you found"
```
(Approve when prompted)

**Then:**
```bash
cody chat "Now list files in /tmp directory"
```
(Approve when prompted)

**Verify:**
- ‚úÖ First tool (readFile) executed
- ‚úÖ Model saw first result, responded
- ‚úÖ Second tool (listDir) executed
- ‚úÖ Model saw second result, responded
- ‚úÖ Both tool results influenced model responses

---

## Test 4: Error Handling - Tool Execution Fails

**Execute:**
```bash
cody chat "Read a file that does not exist: /tmp/nonexistent.txt"
```
(Approve when prompted)

**Expected:**
```
üîß Tool: readFile
Approve? (y/n): y

‚ùå Error: File not found

Assistant: I couldn't read that file because it doesn't exist.
```

**Verify:**
- ‚úÖ Tool attempted
- ‚úÖ Error captured and returned
- ‚úÖ CLI didn't crash
- ‚úÖ Model received error message
- ‚úÖ Model handled gracefully

---

## Success Checklist

After completing all tests:

- [ ] Test 1: Tool approval (approve) works
- [ ] Test 2: Tool approval (deny) works
- [ ] Test 3: Multiple tools in sequence work
- [ ] Test 4: Tool errors handled gracefully

**All tests pass:** Phase 2 functional requirements verified.

**Any test fails:** Document failure, investigate, fix before phase complete.

---

## Notes

**UX observations:**
- Is approval prompt clear?
- Are tool calls easy to understand?
- Do results display well?
- Any improvements for Phase 7 (Polish)?

User experience feedback helps refine UX in later phases.


---

FINAL QUALITY CHECK:

Before declaring phase complete:

Run: npm run format && npm run lint && npx tsc --noEmit && npm test

ALL must pass. Document results.
Update checklist.md and decisions.md.
Commit and push.
Ready for verification stages.

===== END CODER PROMPT =====
