# Cody CLI - Base Operations Reference

**Version:** 0.1.0 (as of Project 02, Phase 5)
**Audience:** Developers, Scripters, and Agents using the `cody` CLI
**Purpose:** A comprehensive, low-level reference for all CLI operations, treating the CLI as a scriptable API.

---

## 1. Overview (25,000 ft)

The `cody` Command-Line Interface is a low-level, scriptable "API" for the Codex agent core. It is designed for both interactive human use and automated execution by other agents or scripts. It intentionally avoids a rich TUI in favor of simple, composable commands that expose the power of the underlying library in a predictable way.

The CLI operates around three primary functional areas:
*   **Conversation Management:** Creating, interacting with, and managing the lifecycle of conversations.
*   **Configuration Management:** Inspecting and modifying the active LLM provider and API settings.
*   **Authentication Management:** Inspecting and modifying the active authentication method.

The interface is designed to be stateful, tracking an "active" conversation within a session, but also supports stateless, one-shot commands suitable for automation.

---

## 2. Core Abstractions (15,000 ft)

The CLI is a thin presentation layer that wraps the `@openai/codex-core` library, primarily interacting with the `ConversationManager`.

```ascii
+-------------------------------------------------+
|              External User / Agent              |
+-----------------------+-------------------------+
                        |
                        v
+-------------------------------------------------+
|                cody CLI Interface               |
| (Commands: new, chat, list, resume, set-*, ...) |
+-----------------------+-------------------------+
                        | (Calls methods on...)
                        v
+-------------------------------------------------+
|        @openai/codex-core Library Layer         |
|                                                 |
|      +-----------------------------------+      |
|      |      ConversationManager          |      |
|      +-----------------------------------+      |
|                        | (Manages...)           |
|      +---------------+ +---------------+        |
|      | Conversation  | | Conversation  | ...    |
|      +---------------+ +---------------+        |
|                                                 |
+-------------------------------------------------+
```

### The Active Conversation

The CLI maintains a concept of an "active" conversation. When a new conversation is created with `cody new` or resumed with `cody resume`, it is set as the active context. Subsequent commands like `cody chat` automatically target this active conversation. This provides a stateful, interactive experience. The active conversation is stored locally and does not persist between shell sessions unless explicitly resumed.

### Configuration Layers

The CLI's behavior is determined by a configuration file located at `~/.cody/config.toml`. This file specifies the default provider, model, authentication method, and other settings. CLI commands like `set-provider` and `set-auth` modify this file to persist changes.

### Authentication Methods

The CLI supports multiple authentication strategies, from simple API keys to reading OAuth tokens generated by other applications (e.g., the official ChatGPT or Claude CLIs). This allows users to leverage their existing accounts without re-authenticating.

---

## 3. Command Reference (5,000 ft -> 1,000 ft)

This section provides a detailed, low-level reference for each command, grouped by functionality.

### Group: Conversation Lifecycle

These commands manage the creation, interaction, and persistence of conversations.

---

#### **`cody new`**

Creates a new, empty conversation and sets it as the active conversation for the current session.

*   **Signature:** `cody new [options]`
*   **Options:**
    *   `--provider <name>`: Override the default provider (e.g., `openai`, `anthropic`).
    *   `--api <name>`: Override the default API for the provider (e.g., `responses`, `chat`).
    *   `--model <name>`: Override the default model.
*   **Behavior:**
    1.  Reads the current configuration from `~/.cody/config.toml`.
    2.  Applies any command-line overrides (`--provider`, etc.).
    3.  Calls the `ConversationManager.newConversation()` method with the final configuration.
    4.  The `ConversationManager` initializes a new `CodexConversation` instance.
    5.  A unique `conversationId` (e.g., `conv_xxxxxxxx`) is generated.
    6.  The new conversation is stored in the CLI's active session state.
    7.  The `conversationId` is printed to standard output.

*   **Example Usage:**
    ```bash
    $ cody new
    ✓ Created new conversation: conv_a1b2c3d4
    ```

---

#### **`cody chat`**

Sends a message to the currently active conversation and prints the model's response.

*   **Signature:** `cody chat <message>`
*   **Arguments:**
    *   `<message>` (required): The string content of the user's message. Must be quoted if it contains spaces.
*   **Behavior:**
    1.  Checks for an active conversation in the current session. If none exists, it prints an error.
    2.  Retrieves the active `CodexConversation` object.
    3.  Calls the `conversation.submit()` method with the user's message.
    4.  The core library sends the message and all previous history to the configured LLM provider.
    5.  The CLI listens for events from the library. As `agent_message` or tool-related events are received, they are rendered to standard output.
    6.  If the model requests tool calls, the CLI will prompt for approval (if required by the policy) before execution.
    7.  The command exits after the model's final response is received (`task_complete` event).

*   **Example Usage:**
    ```bash
    $ cody chat "Hello, world"
    Assistant: Hello! How can I help you today?
    ```

---

#### **`cody list`**

Lists all previously saved conversations from the persistence directory.

*   **Signature:** `cody list`
*   **Behavior:**
    1.  Calls the `ConversationManager.listConversations()` method.
    2.  The manager delegates to the `RolloutRecorder`, which scans the `~/.cody/conversations/` directory.
    3.  It reads metadata (ID, last updated timestamp, provider, model) from each `.jsonl` file.
    4.  The command receives an array of conversation metadata.
    5.  The metadata is formatted into a human-readable table and printed to standard output, sorted by the last update time (most recent first).
    6.  If no conversations are found, it prints a helpful message.

*   **Example Usage:**
    ```bash
    $ cody list

    Saved Conversations:

      conv_a1b2c3d4
        Provider: openai (gpt-4o-mini)
        Updated: 11/15/2025, 2:30:15 PM

      conv_e5f6g7h8
        Provider: anthropic (claude-3-haiku)
        Updated: 11/15/2025, 1:15:00 PM

    Total: 2 conversation(s)
    ```

---

#### **`cody resume`**

Loads a previously saved conversation from its JSONL file and sets it as the active conversation.

*   **Signature:** `cody resume <conversationId>`
*   **Arguments:**
    *   `<conversationId>` (required): The ID of the conversation to resume (e.g., `conv_a1b2c3d4`).
*   **Behavior:**
    1.  Calls `ConversationManager.resumeConversation(conversationId)`.
    2.  The manager constructs the path to `~/.cody/conversations/<conversationId>.jsonl`.
    3.  It uses the `RolloutRecorder` to read the entire JSONL file line by line.
    4.  Each line (a "turn") is parsed, and the full conversation history is reconstructed in memory.
    5.  A new `CodexConversation` instance is created and initialized with this reconstructed history.
    6.  The resumed conversation is set as the active conversation for the current session.
    7.  A confirmation message is printed to standard output.
    8.  If the ID does not exist or the file is corrupt, a specific error is printed.

    ```ascii
    +----------------+   1. resume(id)   +-----------------------+   2. readRollout(id)   +-------------------+
    |    cody CLI    | ----------------> |  ConversationManager  | ---------------------> |  RolloutRecorder  |
    +----------------+                   +-----------------------+                      +---------+---------+
          ^                                                                                       | 3. Read file
          | 6. Set active conv                                                                    v
          |                                                                             +-------------------+
          | 5. Return Conversation                                                      |  ~/.cody/conv.jsonl |
          |                                                                             +-------------------+
          |                      +-----------------------+                                        ^
          +--------------------  |   CodexConversation   | <--------------------------------------+
                                 +-----------------------+      4. Reconstruct History
    ```

*   **Example Usage:**
    ```bash
    $ cody resume conv_a1b2c3d4
    ✓ Resumed conversation: conv_a1b2c3d4

    $ cody chat "Do you remember what we discussed?"
    Assistant: Yes, we were discussing...
    ```

---

### Group: Configuration Management

These commands inspect and modify the active LLM provider configuration.

---

#### **`cody list-providers`**

Displays a list of all available LLM providers and their supported APIs.

*   **Signature:** `cody list-providers`
*   **Behavior:**
    1.  Reads the static, built-in provider information from the core library.
    2.  Reads the current user configuration from `~/.cody/config.toml` to identify the active provider.
    3.  Formats this information into a table, indicating the currently active provider with an arrow (`→`).

*   **Example Usage:**
    ```bash
    $ cody list-providers

    Available Providers:

      Provider    APIs
      ------------------------------------
    → openai      responses, chat
      anthropic   messages
    ```

---

#### **`cody set-provider`**

Sets the default LLM provider and, optionally, the default API and model.

*   **Signature:** `cody set-provider <name> [options]`
*   **Arguments:**
    *   `<name>` (required): The name of the provider to set as default (e.g., `openai`, `anthropic`).
*   **Options:**
    *   `--api <api>`: Also set the default API for this provider (e.g., `chat`).
    *   `--model <model>`: Also set the default model for this provider.
*   **Behavior:**
    1.  Reads the existing configuration from `~/.cody/config.toml`.
    2.  Updates the `[provider]` table with the new values.
    3.  Writes the updated configuration back to `~/.cody/config.toml`.
    4.  Prints a confirmation message.

*   **Example Usage:**
    ```bash
    $ cody set-provider anthropic --model claude-3-opus
    ✓ Provider set to anthropic (messages)
      Model: claude-3-opus
    ```

---

#### **`cody set-api`**

Sets the default API for the currently active provider.

*   **Signature:** `cody set-api <name>`
*   **Arguments:**
    *   `<name>` (required): The name of the API to set (e.g., `responses`, `chat`).
*   **Behavior:**
    1.  Reads the existing configuration from `~/.cody/config.toml`.
    2.  Validates that the specified API is supported by the current provider.
    3.  Updates the `[provider]` table with the new API value.
    4.  Writes the updated configuration back to `~/.cody/config.toml`.
    5.  Prints a confirmation message.

*   **Example Usage:**
    ```bash
    $ cody set-api chat
    ✓ API set to chat for provider openai
    ```

---

### Group: Authentication Management

These commands inspect and modify the active authentication method.

---

#### **`cody login`**

Displays the status of all available authentication methods.

*   **Signature:** `cody login`
*   **Behavior:**
    1.  Calls the `AuthManager` to check the status of each configured authentication method.
    2.  For API keys, it checks if the key is present in `~/.cody/config.toml`.
    3.  For OAuth methods, it checks if the corresponding token file exists (e.g., `~/.cody/oauth/chatgpt.json`).
    4.  It formats the status into a list, indicating which methods are configured (`✓`/`✗`) and which one is currently active (`→`).

*   **Example Usage:**
    ```bash
    $ cody login

    Authentication Status:

      Method              Configured
      ----------------------------------
    → openai-api-key      ✓
      anthropic-api-key   ✗
      oauth-chatgpt       ✓
      oauth-claude        ✗
    ```

---

#### **`cody set-auth`**

Sets the default authentication method to use.

*   **Signature:** `cody set-auth <method>`
*   **Arguments:**
    *   `<method>` (required): The authentication method to set as default (e.g., `openai-api-key`, `oauth-chatgpt`).
*   **Behavior:**
    1.  Reads the existing configuration from `~/.cody/config.toml`.
    2.  Updates the `[auth]` table to set the `method` field to the new value.
    3.  Writes the updated configuration back to `~/.cody/config.toml`.
    4.  Prints a confirmation message.

*   **Example Usage:**
    ```bash
    $ cody set-auth oauth-chatgpt
    ✓ Auth method set to oauth-chatgpt
    ```
