===== PHASE 6: CODER PROMPT =====
ROLE: Senior TypeScript developer implementing phases of the Cody CLI integration project. You write clean, tested code following TDD principles with mocked-service tests at library boundaries.


---

PRODUCT:

**Cody** is a command-line interface for the Codex TypeScript library. It provides multi-provider LLM agent capabilities supporting OpenAI (Responses, Chat) and Anthropic (Messages) APIs with tool execution, conversation persistence, and structured tool calling. Built as a TypeScript port of OpenAI's Rust-based Codex CLI, Cody serves as both a standalone CLI tool and reference implementation for the @openai/codex-core library.


---

PROJECT CONTEXT:

# Project 02: UI Integration & Library Definition

## What We're Building

Project 02 integrates all ported Codex modules (Phases 1-6) into a working command-line interface called **Cody** and defines the library API surface for @openai/codex-core. This project validates the Rust → TypeScript port by wiring protocol, configuration, persistence, execution, client, tools, and orchestration layers into complete conversation flows.

## Why It Matters

The port is functionally complete but untested as an integrated system. Individual modules have unit tests, but we haven't verified end-to-end workflows. This project proves the port works, exposes integration issues, and establishes the library interface that external developers will use.

## Project Success Criteria

By project completion:
- User can create conversations, send messages, receive responses (all providers: OpenAI Responses/Chat, Anthropic Messages)
- All auth methods work (API keys, ChatGPT OAuth, Claude OAuth)
- Tools execute with approval flow
- Conversations persist and resume (JSONL format)
- MCP integration functional
- Library API documented (public exports, usage examples)
- REST API designed (optional implementation)
- Zero-error quality baseline maintained (0 TS errors, 0 ESLint errors, all tests passing)

## Dependencies

- Phase 6 complete (75 modules ported, 1,876 tests passing)
- Phase 5.2 complete (quality baseline clean)
- API keys: OpenAI, Anthropic, OpenRouter
- OAuth tokens: Read from ~/.codex (ChatGPT), ~/.claude (Claude)

## Scope

**In scope:** CLI commands, provider integration (3 APIs), auth methods (4 total), tool execution, persistence/resume, library API docs, REST API spec

**Non-scope:** Script harness (Project 03), memory innovations (Projects 04-06), rich TUI, additional tools, performance optimization, production hardening


---

PHASE 6 TECHNICAL DESIGN:

# Phase 6: Technical Design

**Phase:** Library API & REST API
**Goal:** Document @openai/codex-core public API surface, implement Fastify REST wrapper with Bun runtime, comprehensive Playwright testing in two modes

---

## Integration Overview

(From TECH-APPROACH Section 7)

Phase 6 completes the integration project by documenting the library API surface and implementing a REST API wrapper. The library API defines what external developers can import from @openai/codex-core (ConversationManager, Conversation, types, utilities). The REST API provides HTTP endpoints for the same capabilities, enabling web/mobile clients and service-to-service communication. Both APIs expose the same underlying functionality—library via TypeScript imports, REST via HTTP.

The REST API uses Fastify (fast, minimal overhead) running on Bun (faster runtime than Node). Each endpoint maps to library methods—POST /conversations calls ConversationManager.createConversation(), POST /conversations/{id}/messages calls conversation.sendMessage(), etc. The API layer is thin—validation, error handling, HTTP formatting, but business logic stays in library. This proves the library is well-designed (if API can consume it cleanly, so can other applications).

Testing uses Playwright for REST API (not vitest—this is HTTP-level testing). Two test modes: mocked (models and external APIs stubbed, tests many scenarios and permutations) and non-mocked (real models and APIs, key scenarios only to verify actual functionality without burning time/cost). Mocked tests run in CI, non-mocked tests run manually before release.

### Phase 6 Target State

```
External Developers
        ↓
   ┌────┴────┐
   ▼         ▼
Library    REST API
Import     HTTP
           ↓
    ┌──────────────────────┐
    │  Fastify + Bun       │
    │  ┌────────────────┐  │
    │  │  POST /convs   │  │
    │  │  POST /message │  │
    │  │  GET  /convs   │  │
    │  └────────┬───────┘  │
    └───────────┼──────────┘
                ▼
    ┌──────────────────────┐
    │  @openai/codex-core  │
    │  ┌────────────────┐  │
    │  │ Conversation   │  │
    │  │   Manager      │  │
    │  └────────────────┘  │
    └──────────────────────┘
            ↓
    [Library layer from Phases 1-5]

Testing:
├── Playwright (REST API)
│   ├── Mocked (models + APIs stubbed)
│   └── Non-mocked (real LLMs, key scenarios)
└── Mocked-service (Library, from Phases 1-5)
```

**Highlighted:** Library exports documented (public API surface), REST API implementation (Fastify + Bun), Playwright test suite (two modes).

---

## Technical Deltas

**New code (library API):**
- src/index.ts: Main library export file (~50 lines)
- docs/api/library-api.md: Complete API documentation (~400 lines)

**New code (REST API):**
- src/api/server.ts: Fastify server setup (~80 lines)
- src/api/routes/conversations.ts: Conversation CRUD endpoints (~120 lines)
- src/api/routes/messages.ts: Message send/history endpoints (~100 lines)
- src/api/routes/config.ts: Config endpoints (~60 lines)
- src/api/middleware/auth.ts: API key authentication (~40 lines)
- src/api/middleware/error.ts: Error handling (~50 lines)
- docs/api/rest-api.md: REST API specification (~500 lines)

**New code (Playwright testing):**
- tests/playwright/api/conversations.spec.ts: Conversation tests (~150 lines, 15 tests)
- tests/playwright/api/messages.spec.ts: Message tests (~200 lines, 20 tests)
- tests/playwright/api/providers.spec.ts: Provider parity (~120 lines, 12 tests)
- tests/playwright/api/auth.spec.ts: Auth tests (~80 lines, 8 tests)
- tests/playwright/mocks/model-server.ts: Mock LLM APIs (~200 lines)
- tests/playwright/mocks/search-server.ts: Mock search APIs (~80 lines)
- tests/playwright/config/: Test configurations (~50 lines)
- tests/playwright/fixtures/: Preset responses (~100 lines)

**Estimated new code:** ~2,380 lines total
- Library exports + docs: ~450 lines
- REST API + docs: ~950 lines
- Playwright tests + mocks: ~980 lines

**This is the largest phase by code volume** (but much is boilerplate routes and test scenarios).

---

## Library API Design

### Public Exports

**Main entry point:** `src/index.ts`

```typescript
// Primary API
export {ConversationManager} from './core/conversation-manager';
export {CodexConversation} from './core/codex-conversation';

// Factory helper
export {createConversationManager} from './core/factory';

// Types
export type {
  ConversationConfig,
  ConversationMetadata,
  AuthMethod,
  Provider,
  WireApi
} from './core/types';

export type {
  ResponseItem,
  ResponseItems,
  FunctionCall,
  FunctionCallOutput,
  UserInput
} from './protocol/items';

// Utilities (optional, if useful for external devs)
export {countTokens} from './utils/tokenizer';
export {parseRollout} from './core/rollout/parser';
```

**What NOT to export:**
- Internal Session class (implementation detail)
- Codex class (wrapped by CodexConversation)
- ModelClient implementations (factory handles)
- ToolRouter internals (handled by Session)

**Principle:** Export only what external developers need. Keep internal implementation hidden.

### Factory Helper

**Purpose:** Simplify library usage for common case.

```typescript
// src/core/factory.ts

export async function createConversationManager(options?: {
  configPath?: string;
  baseDir?: string;
}): Promise<ConversationManager> {
  // Load config
  const configPath = options?.configPath ?? '~/.cody/config.toml';
  const config = await loadConfig(configPath);
  
  // Create dependencies
  const authManager = new AuthManager(config);
  const recorder = new RolloutRecorder(options?.baseDir ?? '~/.cody/conversations');
  
  // Create manager
  return new ConversationManager(authManager, recorder);
}
```

**Usage:**
```typescript
import {createConversationManager} from '@openai/codex-core';

// Simple (uses defaults)
const manager = await createConversationManager();

// Custom paths
const manager = await createConversationManager({
  configPath: './my-config.toml',
  baseDir: './my-conversations'
});
```

### Usage Examples

**Example 1: Basic Chat**
```typescript
import {createConversationManager} from '@openai/codex-core';

const manager = await createConversationManager();

const {conversation, conversationId} = await manager.newConversation({
  provider: {name: 'openai', api: 'responses', model: 'gpt-4o-mini'},
  auth: {method: 'openai-api-key'}
});

await conversation.submit([{type: 'text', text: 'Hello!'}]);
const event = await conversation.nextEvent();

console.log(event.msg); // Assistant response
```

**Example 2: Multi-Turn with Tools**
```typescript
const {conversation} = await manager.newConversation(config);

// Enable tool execution with approval callback
const approvalCallback = async (toolName, args) => {
  console.log(`Approve ${toolName}?`, args);
  return true; // Auto-approve for this example
};

// Send message that triggers tools
await conversation.submit([{type: 'text', text: 'Read the README file'}]);

// Process events
while (true) {
  const event = await conversation.nextEvent();
  
  if (event.msg.type === 'tool_call') {
    const approved = await approvalCallback(event.msg.name, event.msg.args);
    // Handle approval...
  }
  
  if (event.msg.type === 'completed') {
    break;
  }
}
```

**Example 3: Resume**
```typescript
// List saved conversations
const conversations = await manager.listConversations();
console.log('Saved:', conversations.map(c => c.id));

// Resume specific conversation
const conversation = await manager.resumeConversation('conv_abc123');

// Continue chatting
await conversation.submit([{type: 'text', text: 'Continuing from before...'}]);
```

**These examples go in docs/api/library-api.md.**

---

## REST API Design

### Endpoint Specification

**Base URL:** `http://localhost:3000/api/v1`

**Conversation Endpoints:**

```
POST   /conversations
GET    /conversations
GET    /conversations/:id
DELETE /conversations/:id
POST   /conversations/:id/resume
```

**Message Endpoints:**

```
POST   /conversations/:id/messages
GET    /conversations/:id/messages
```

**Config Endpoints:**

```
GET    /config
POST   /config/provider
POST   /config/auth
```

### Request/Response Formats

**POST /api/v1/conversations** (Create)

Request:
```json
{
  "provider": "openai",
  "api": "responses",
  "model": "gpt-4o-mini",
  "auth": {
    "method": "openai-api-key"
  }
}
```

Response (201 Created):
```json
{
  "conversationId": "conv_abc123",
  "created": 1699564800000,
  "provider": "openai",
  "api": "responses",
  "model": "gpt-4o-mini"
}
```

**POST /api/v1/conversations/:id/messages** (Send Message)

Request:
```json
{
  "message": "Hello, how are you?",
  "stream": false
}
```

Response (200 OK):
```json
{
  "items": [
    {
      "type": "message",
      "role": "assistant",
      "content": [
        {"type": "text", "text": "I'm doing well, thank you!"}
      ]
    }
  ],
  "usage": {
    "inputTokens": 15,
    "outputTokens": 12,
    "totalTokens": 27
  }
}
```

**GET /api/v1/conversations** (List)

Response (200 OK):
```json
{
  "conversations": [
    {
      "id": "conv_abc123",
      "provider": "openai",
      "model": "gpt-4o-mini",
      "updatedAt": 1699564800000
    },
    {
      "id": "conv_def456",
      "provider": "anthropic",
      "model": "claude-3-haiku",
      "updatedAt": 1699564700000
    }
  ]
}
```

**Error Response Format:**

```json
{
  "error": {
    "code": "CONVERSATION_NOT_FOUND",
    "message": "Conversation 'conv_xyz' not found",
    "details": {
      "conversationId": "conv_xyz"
    }
  }
}
```

HTTP status codes:
- 200: Success
- 201: Created
- 400: Bad Request (validation error)
- 401: Unauthorized (missing/invalid API key)
- 404: Not Found (conversation doesn't exist)
- 500: Internal Server Error

### Authentication

**Two-layer auth:**

**Layer 1: REST API Access**
- Header: `Authorization: Bearer <api-key>`
- Validates request can access REST API
- Simple API key check (not OAuth)

**Layer 2: Model Provider Auth**
- Configured per conversation (in request body)
- Uses AuthManager (API keys or OAuth)
- Handled by library layer

**Example request:**
```bash
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer my-rest-api-key" \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "openai",
    "api": "responses",
    "model": "gpt-4o-mini",
    "auth": {"method": "openai-api-key"}
  }'
```

**REST API key** (Bearer token) authorizes API access.
**Model provider auth** (in body) authorizes LLM API calls.

---

## Fastify Server Implementation

### Server Setup

```typescript
// src/api/server.ts

import Fastify from 'fastify';
import {conversationRoutes} from './routes/conversations';
import {messageRoutes} from './routes/messages';
import {configRoutes} from './routes/config';
import {authMiddleware} from './middleware/auth';
import {errorMiddleware} from './middleware/error';

export async function createServer(options?: {
  port?: number;
  apiKey?: string;
}) {
  const fastify = Fastify({
    logger: true,
    requestIdHeader: 'x-request-id'
  });

  // Middleware
  fastify.addHook('onRequest', authMiddleware(options?.apiKey));
  fastify.setErrorHandler(errorMiddleware);

  // Routes
  await fastify.register(conversationRoutes, {prefix: '/api/v1'});
  await fastify.register(messageRoutes, {prefix: '/api/v1'});
  await fastify.register(configRoutes, {prefix: '/api/v1'});

  // Health check
  fastify.get('/health', async () => ({status: 'ok'}));

  return fastify;
}

export async function startServer(port: number = 3000) {
  const server = await createServer({
    apiKey: process.env.CODY_API_KEY
  });

  await server.listen({
    port,
    host: '0.0.0.0'
  });

  console.log(`✓ Cody REST API listening on http://localhost:${port}`);
  return server;
}
```

**Run with Bun:**
```bash
bun run src/api/server.ts
```

### Route Handlers

**Conversation Routes:**

```typescript
// src/api/routes/conversations.ts

import {FastifyInstance} from 'fastify';
import {getConversationManager} from '../manager';

export async function conversationRoutes(fastify: FastifyInstance) {
  const manager = getConversationManager();

  // Create conversation
  fastify.post('/conversations', async (request, reply) => {
    const {provider, api, model, auth} = request.body as CreateConversationRequest;

    // Validate request
    if (!provider || !api || !model) {
      return reply.code(400).send({
        error: {
          code: 'INVALID_REQUEST',
          message: 'Missing required fields: provider, api, model'
        }
      });
    }

    try {
      const {conversation, conversationId} = await manager.newConversation({
        provider: {name: provider, api, model},
        auth
      });

      return reply.code(201).send({
        conversationId: conversationId.toString(),
        created: Date.now(),
        provider,
        api,
        model
      });
    } catch (err) {
      throw err; // Error middleware handles
    }
  });

  // List conversations
  fastify.get('/conversations', async (request, reply) => {
    const conversations = await manager.listConversations();

    return {
      conversations: conversations.map(c => ({
        id: c.id,
        provider: c.provider,
        model: c.model,
        updatedAt: c.updatedAt
      }))
    };
  });

  // Get conversation
  fastify.get('/conversations/:id', async (request, reply) => {
    const {id} = request.params as {id: string};

    const conversation = await manager.getConversation(id);
    if (!conversation) {
      return reply.code(404).send({
        error: {
          code: 'CONVERSATION_NOT_FOUND',
          message: `Conversation '${id}' not found`
        }
      });
    }

    return {
      id,
      // Return metadata (provider, model, message count, etc.)
    };
  });

  // Delete conversation
  fastify.delete('/conversations/:id', async (request, reply) => {
    const {id} = request.params as {id: string};

    await manager.removeConversation(id);

    return reply.code(204).send();
  });

  // Resume conversation
  fastify.post('/conversations/:id/resume', async (request, reply) => {
    const {id} = request.params as {id: string};

    try {
      const conversation = await manager.resumeConversation(id);

      return {
        conversationId: id,
        resumed: true
      };
    } catch (err) {
      if (err.code === 'CONVERSATION_NOT_FOUND') {
        return reply.code(404).send({
          error: {
            code: 'CONVERSATION_NOT_FOUND',
            message: `Conversation '${id}' not found`
          }
        });
      }
      throw err;
    }
  });
}
```

**Message Routes:**

```typescript
// src/api/routes/messages.ts

export async function messageRoutes(fastify: FastifyInstance) {
  const manager = getConversationManager();

  // Send message
  fastify.post('/conversations/:id/messages', async (request, reply) => {
    const {id} = request.params as {id: string};
    const {message, stream} = request.body as SendMessageRequest;

    if (!message) {
      return reply.code(400).send({
        error: {
          code: 'INVALID_REQUEST',
          message: 'Missing required field: message'
        }
      });
    }

    const conversation = await manager.getConversation(id);
    if (!conversation) {
      return reply.code(404).send({
        error: {
          code: 'CONVERSATION_NOT_FOUND',
          message: `Conversation '${id}' not found`
        }
      });
    }

    // Submit message
    await conversation.submit([{type: 'text', text: message}]);

    if (stream) {
      // SSE streaming mode
      reply.raw.writeHead(200, {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive'
      });

      // Stream events
      while (true) {
        const event = await conversation.nextEvent();

        reply.raw.write(`data: ${JSON.stringify(event.msg)}\n\n`);

        if (event.msg.type === 'completed') {
          break;
        }
      }

      reply.raw.end();
      return reply;
    } else {
      // Batch mode - collect all events
      const items = [];
      let usage = null;

      while (true) {
        const event = await conversation.nextEvent();

        if (event.msg.type === 'message') {
          items.push(event.msg);
        }

        if (event.msg.type === 'completed') {
          usage = event.msg.usage;
          break;
        }
      }

      return {items, usage};
    }
  });

  // Get message history
  fastify.get('/conversations/:id/messages', async (request, reply) => {
    const {id} = request.params as {id: string};

    const conversation = await manager.getConversation(id);
    if (!conversation) {
      return reply.code(404).send({
        error: {code: 'CONVERSATION_NOT_FOUND', message: `Conversation '${id}' not found`}
      });
    }

    const history = conversation.getHistory(); // Or equivalent method

    return {
      conversationId: id,
      messages: history
    };
  });
}
```

### Middleware

**Auth Middleware:**

```typescript
// src/api/middleware/auth.ts

export function authMiddleware(expectedApiKey?: string) {
  return async (request, reply) => {
    // Skip auth for health check
    if (request.url === '/health') {
      return;
    }

    const authHeader = request.headers.authorization;

    if (!authHeader) {
      return reply.code(401).send({
        error: {
          code: 'UNAUTHORIZED',
          message: 'Missing Authorization header'
        }
      });
    }

    const [scheme, token] = authHeader.split(' ');

    if (scheme !== 'Bearer') {
      return reply.code(401).send({
        error: {
          code: 'UNAUTHORIZED',
          message: 'Invalid authorization scheme. Use: Bearer <token>'
        }
      });
    }

    if (expectedApiKey && token !== expectedApiKey) {
      return reply.code(401).send({
        error: {
          code: 'UNAUTHORIZED',
          message: 'Invalid API key'
        }
      });
    }

    // Auth passed
  };
}
```

**Error Middleware:**

```typescript
// src/api/middleware/error.ts

export function errorMiddleware(error, request, reply) {
  // Map internal errors to HTTP responses

  if (error.name === 'ConfigurationError') {
    return reply.code(400).send({
      error: {
        code: 'CONFIGURATION_ERROR',
        message: error.message
      }
    });
  }

  if (error.name === 'AuthError') {
    return reply.code(401).send({
      error: {
        code: 'AUTH_ERROR',
        message: error.message
      }
    });
  }

  if (error.code === 'CONVERSATION_NOT_FOUND') {
    return reply.code(404).send({
      error: {
        code: 'CONVERSATION_NOT_FOUND',
        message: error.message
      }
    });
  }

  // Default: 500
  return reply.code(500).send({
    error: {
      code: 'INTERNAL_ERROR',
      message: error.message || 'An unexpected error occurred'
    }
  });
}
```

---

## Component Structure

REST API is thin wrapper. Routes validate and format, middleware handles cross-cutting concerns, library does all business logic.

```mermaid
classDiagram
    class FastifyApp {
        +register(routes)
        +addHook(middleware)
        +listen(port)
        +get(path, handler)
        +post(path, handler)
    }

    class ConversationRoutes {
        +POST create(req, res)
        +GET list(req, res)
        +GET get(req, res)
        +DELETE delete(req, res)
        +POST resume(req, res)
    }

    class MessageRoutes {
        +POST send(req, res)
        +GET history(req, res)
    }

    class ConfigRoutes {
        +GET getConfig(req, res)
        +POST setProvider(req, res)
        +POST setAuth(req, res)
    }

    class AuthMiddleware {
        +validateRequest(req, res)
        -extractToken(headers)
        -validateApiKey(token)
    }

    class ErrorMiddleware {
        +handleError(error, req, res)
        -mapErrorToHttp(error)
        -formatErrorResponse(error)
    }

    class ConversationManager {
        +newConversation(config)
        +getConversation(id)
        +listConversations()
        +resumeConversation(id)
        +removeConversation(id)
    }

    FastifyApp --> ConversationRoutes: registers
    FastifyApp --> MessageRoutes: registers
    FastifyApp --> ConfigRoutes: registers
    FastifyApp --> AuthMiddleware: uses
    FastifyApp --> ErrorMiddleware: uses
    ConversationRoutes --> ConversationManager: calls
    MessageRoutes --> ConversationManager: calls
    ConfigRoutes --> ConversationManager: calls
```

---

## Playwright Testing Strategy

**Two test modes for comprehensive coverage:**

### Mode 1: Mocked (CI/Development)

**Environment:** `TEST_MODE=mocked`

**Mock servers:**
- Mock OpenAI API (localhost:3001)
- Mock Anthropic API (localhost:3002)
- Mock OpenRouter API (localhost:3003)
- Mock search APIs (localhost:3004)

**What's mocked:**
- All LLM API calls (return preset responses)
- All search API calls (return preset results)
- Filesystem (use temp directories)
- Keyring (return test tokens)

**Test coverage:**
- Full scenario matrix (providers × auth × workflows)
- Error cases (400, 401, 404, 500)
- Edge cases (empty messages, large responses, concurrent requests)
- Security tests (missing auth, invalid tokens, injection attempts)

**Benefits:**
- Fast (~2 minutes for ~55 tests)
- Deterministic (no flaky network)
- Comprehensive (test all permutations)
- No cost (no real API calls)
- Runnable offline

**Run via:** `npm run test:playwright:mocked`

### Mode 2: Non-Mocked (Validation)

**Environment:** `TEST_MODE=integration`

**Real APIs:**
- OpenAI Responses (gpt-4o-mini)
- Anthropic Messages (haiku-4.5)
- OpenRouter (gemini-2.0-flash-001)

**What's real:**
- LLM API calls (actual network, actual models)
- Auth (real API keys)
- Responses (real model behavior)

**Test coverage (minimal, key scenarios only):**
- Happy path per provider (create → send → receive)
- Tool execution (one tool call per provider)
- Thinking parameter (Responses + Messages with thinking)
- Temperature (verify variation)
- Persistence (save → resume)

**Benefits:**
- Validates real behavior
- Catches provider quirks
- Proves actual functionality

**Cost:**
- ~5 minutes runtime
- ~$0.05-0.10 in API costs
- Manual run only (not CI)

**Run via:** `npm run test:playwright:integration`

### Mock Server Implementation

**Mock Model API Server:**

```typescript
// tests/playwright/mocks/model-server.ts

import {createServer} from 'http';

export function startMockModelServer(port: number = 3001) {
  const server = createServer((req, res) => {
    // Parse request
    const url = new URL(req.url, `http://localhost:${port}`);

    // OpenAI Responses API
    if (url.pathname === '/v1/chat/completions' && req.headers['openai-api-version']) {
      return handleResponsesAPI(req, res);
    }

    // OpenAI Chat API
    if (url.pathname === '/v1/chat/completions') {
      return handleChatAPI(req, res);
    }

    // Anthropic Messages API
    if (url.pathname === '/v1/messages') {
      return handleMessagesAPI(req, res);
    }

    // Not found
    res.writeHead(404);
    res.end();
  });

  server.listen(port);
  return server;
}

function handleResponsesAPI(req, res) {
  // Return SSE stream with preset responses
  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'openai-api-version': '2024-10-01'
  });

  // Send events
  res.write('event: response.created\ndata: {"id":"resp_123"}\n\n');
  res.write('event: response.output_item.done\ndata: {"item":{"type":"message","role":"assistant","content":[{"type":"text","text":"Mock response"}]}}\n\n');
  res.write('event: response.done\ndata: {"usage":{"total_tokens":20}}\n\n');

  res.end();
}

// Similar for Chat and Messages APIs
```

**For testing:** Start mock servers before Playwright tests, configure library to use localhost URLs, run tests, verify requests hit mocks.

---

## Playwright Test Structure

**Test organization:**

```
tests/playwright/
├── api/
│   ├── conversations.spec.ts    (15 tests)
│   ├── messages.spec.ts         (20 tests)
│   ├── providers.spec.ts        (12 tests)
│   └── auth.spec.ts             (8 tests)
├── mocks/
│   ├── model-server.ts          (Mock LLM APIs)
│   ├── search-server.ts         (Mock search APIs)
│   └── start-mocks.ts           (Launch all mocks)
├── config/
│   ├── mocked.config.ts         (Mocked mode settings)
│   └── integration.config.ts    (Non-mocked mode settings)
└── fixtures/
    └── responses.ts             (Preset API responses)
```

### Example Playwright Tests

**conversations.spec.ts:**

```typescript
import {test, expect} from '@playwright/test';

test.describe('Conversations API', () => {
  test('creates conversation with OpenAI', async ({request}) => {
    const response = await request.post('/api/v1/conversations', {
      headers: {
        'Authorization': 'Bearer test-api-key',
        'Content-Type': 'application/json'
      },
      data: {
        provider: 'openai',
        api: 'responses',
        model: 'gpt-4o-mini',
        auth: {method: 'openai-api-key'}
      }
    });

    expect(response.ok()).toBeTruthy();
    const body = await response.json();
    expect(body.conversationId).toBeDefined();
    expect(body.provider).toBe('openai');
  });

  test('lists conversations', async ({request}) => {
    // Create a conversation first
    const createResp = await request.post('/api/v1/conversations', {
      headers: {'Authorization': 'Bearer test-api-key'},
      data: {provider: 'openai', api: 'responses', model: 'gpt-4', auth: {method: 'openai-api-key'}}
    });
    const {conversationId} = await createResp.json();

    // List
    const listResp = await request.get('/api/v1/conversations', {
      headers: {'Authorization': 'Bearer test-api-key'}
    });

    expect(listResp.ok()).toBeTruthy();
    const {conversations} = await listResp.json();
    expect(conversations.some(c => c.id === conversationId)).toBe(true);
  });

  test('returns 404 for missing conversation', async ({request}) => {
    const response = await request.get('/api/v1/conversations/nonexistent', {
      headers: {'Authorization': 'Bearer test-api-key'}
    });

    expect(response.status()).toBe(404);
    const body = await response.json();
    expect(body.error.code).toBe('CONVERSATION_NOT_FOUND');
  });

  test('returns 401 without auth header', async ({request}) => {
    const response = await request.post('/api/v1/conversations', {
      data: {provider: 'openai', api: 'responses', model: 'gpt-4', auth: {method: 'openai-api-key'}}
    });

    expect(response.status()).toBe(401);
  });
});
```

**messages.spec.ts:**

```typescript
test.describe('Messages API', () => {
  test('sends message and receives response', async ({request}) => {
    // Create conversation
    const createResp = await request.post('/api/v1/conversations', {
      headers: {'Authorization': 'Bearer test-api-key'},
      data: {provider: 'openai', api: 'responses', model: 'gpt-4', auth: {method: 'openai-api-key'}}
    });
    const {conversationId} = await createResp.json();

    // Send message
    const msgResp = await request.post(`/api/v1/conversations/${conversationId}/messages`, {
      headers: {'Authorization': 'Bearer test-api-key'},
      data: {message: 'Hello', stream: false}
    });

    expect(msgResp.ok()).toBeTruthy();
    const {items, usage} = await msgResp.json();
    expect(items.length).toBeGreaterThan(0);
    expect(items[0].type).toBe('message');
    expect(usage.totalTokens).toBeGreaterThan(0);
  });

  test('streams message with SSE', async ({request}) => {
    const createResp = await request.post('/api/v1/conversations', {
      headers: {'Authorization': 'Bearer test-api-key'},
      data: {provider: 'openai', api: 'responses', model: 'gpt-4', auth: {method: 'openai-api-key'}}
    });
    const {conversationId} = await createResp.json();

    // Send with streaming
    const msgResp = await request.post(`/api/v1/conversations/${conversationId}/messages`, {
      headers: {'Authorization': 'Bearer test-api-key'},
      data: {message: 'Hello', stream: true}
    });

    expect(msgResp.headers()['content-type']).toContain('text/event-stream');

    // Read SSE stream
    const body = await msgResp.text();
    expect(body).toContain('data:');
    // Verify SSE format
  });
});
```

---

## Reference Locations

**Library code (already ported):**
- ConversationManager: `codex-ts/src/core/conversation-manager/`
- CodexConversation: `codex-ts/src/core/codex-conversation.ts`
- Types: `codex-ts/src/protocol/items.ts`, `codex-ts/src/core/types.ts`

**Fastify docs:** https://fastify.dev/docs/latest/
**Playwright docs:** https://playwright.dev/docs/api-testing

---

## Implementation Notes

**Key decisions to document in DECISIONS.md:**

1. **Library exports:** What to export vs keep internal? Principle: export only what external devs need.

2. **REST API authentication:** Simple API key (Bearer token) vs more complex? Recommend: simple for now, can add OAuth later.

3. **Streaming implementation:** SSE format for REST API? Match OpenAI's format or custom? Recommend: custom (simpler), document format.

4. **Error response format:** Consistent structure across all errors? Recommend: {error: {code, message, details}}.

5. **Conversation isolation:** REST API stateless (no session affinity) or stateful? Recommend: stateless (each request independent).

6. **Bun vs Node:** Run with Bun for performance or Node for compatibility? Recommend: Bun (faster, test both).

7. **Mock server complexity:** Full SSE simulation or simple JSON responses? Recommend: full SSE (tests streaming paths).

8. **Playwright test organization:** Group by endpoint or by scenario? Recommend: by endpoint (clearer).

---

## Quality Gates

**Before marking Phase 6 complete:**

1. **Library API:**
   - [ ] docs/api/library-api.md complete (~400 lines)
   - [ ] src/index.ts exports defined
   - [ ] Usage examples work (test with minimal app)
   - [ ] Mocked-service tests repointed to library imports (verify still pass)

2. **REST API:**
   - [ ] All endpoints implemented
   - [ ] docs/api/rest-api.md complete (~500 lines)
   - [ ] Server starts with Bun
   - [ ] Health check works

3. **Playwright (mocked):**
   - [ ] ~55 tests passing
   - [ ] All scenarios covered
   - [ ] Mock servers working
   - [ ] Run time <2 minutes

4. **Playwright (non-mocked):**
   - [ ] ~8 key scenarios passing
   - [ ] Real models tested
   - [ ] Results logged

5. **Quality baseline:**
   - [ ] TypeScript: 0 errors
   - [ ] ESLint: 0 errors
   - [ ] Format: clean
   - [ ] Combined: All checks pass

6. **Code review:**
   - [ ] Stage 1: API design, security, error handling
   - [ ] Stage 2: Library exports clean, REST maps correctly

---

## Summary

Phase 6 exposes the integrated system through two interfaces: TypeScript library and REST API. Library API serves developers building on Codex. REST API serves web/mobile apps and services. Both are thin wrappers around the same core functionality (ConversationManager). Comprehensive Playwright testing in two modes ensures REST API works correctly (mocked for coverage, non-mocked for validation). Focus on clean API design, helpful error messages, and thorough testing across all scenarios.


---

TEST CONDITIONS:

# Phase 6: Test Conditions

**Test Frameworks:**
- Playwright (REST API testing)
- Vitest (library import validation)

**Test Modes:**
- Mocked: Mock LLM APIs, fast, comprehensive
- Non-mocked: Real LLM APIs, slow, key scenarios only

---

## Library API Validation (Vitest)

**File:** `tests/library/exports.test.ts`

### Test 1: Can Import Library
- **Execute:** `import {ConversationManager} from '@openai/codex-core'`
- **Verify:** Import succeeds, ConversationManager is defined

### Test 2: Factory Helper Works
- **Execute:** `import {createConversationManager} from '@openai/codex-core'`
- **Verify:** Can call factory, returns ConversationManager instance

### Test 3: Types Exported
- **Execute:** Import ConversationConfig, AuthMethod, ResponseItem types
- **Verify:** All types available, TypeScript compilation succeeds

### Test 4: Existing Mocked-Service Tests Work with Library Imports
- **Execute:** Update phase 1-5 mocked-service tests to import from '@openai/codex-core' instead of relative paths
- **Verify:** All tests still pass (library exports work)

---

## Playwright Mocked Mode Tests

**Environment:** `TEST_MODE=mocked`
**Base URL:** `http://localhost:3000`
**Mock APIs:** localhost:3001-3004

### Suite 1: Conversations API (15 tests)

**File:** `tests/playwright/api/conversations.spec.ts`

**Test 1: Create Conversation (OpenAI Responses)**
- **Request:** POST /conversations with provider=openai, api=responses
- **Verify:** 201 Created, returns conversationId, provider, model

**Test 2: Create Conversation (Anthropic Messages)**
- **Request:** POST /conversations with provider=anthropic, api=messages
- **Verify:** 201 Created, returns conversationId

**Test 3: Create with Invalid Provider**
- **Request:** POST /conversations with provider=invalid
- **Verify:** 400 Bad Request, error.code='CONFIGURATION_ERROR'

**Test 4: Create with Missing Fields**
- **Request:** POST /conversations with missing model field
- **Verify:** 400 Bad Request, error message lists missing fields

**Test 5: Create Without Auth Header**
- **Request:** POST /conversations without Authorization header
- **Verify:** 401 Unauthorized

**Test 6: Create with Invalid API Key**
- **Request:** POST /conversations with wrong Bearer token
- **Verify:** 401 Unauthorized

**Test 7: List Conversations**
- **Setup:** Create 3 conversations
- **Request:** GET /conversations
- **Verify:** Returns array with 3 items, all have id/provider/model/updatedAt

**Test 8: List When Empty**
- **Request:** GET /conversations (no conversations created)
- **Verify:** Returns {conversations: []}

**Test 9: Get Conversation**
- **Setup:** Create conversation
- **Request:** GET /conversations/:id
- **Verify:** Returns conversation metadata

**Test 10: Get Missing Conversation**
- **Request:** GET /conversations/nonexistent
- **Verify:** 404 Not Found, error.code='CONVERSATION_NOT_FOUND'

**Test 11: Delete Conversation**
- **Setup:** Create conversation
- **Request:** DELETE /conversations/:id
- **Verify:** 204 No Content, conversation removed

**Test 12: Delete Missing Conversation**
- **Request:** DELETE /conversations/nonexistent
- **Verify:** 404 Not Found

**Test 13: Resume Conversation**
- **Setup:** Create conversation, send messages, get ID
- **Request:** POST /conversations/:id/resume
- **Verify:** Returns {conversationId, resumed: true}

**Test 14: Resume Missing Conversation**
- **Request:** POST /conversations/nonexistent/resume
- **Verify:** 404 Not Found

**Test 15: Concurrent Conversation Creation**
- **Execute:** Create 5 conversations in parallel (Promise.all)
- **Verify:** All succeed, all have unique IDs

### Suite 2: Messages API (20 tests)

**File:** `tests/playwright/api/messages.spec.ts`

**Test 16: Send Message (Batch Mode)**
- **Setup:** Create conversation
- **Request:** POST /conversations/:id/messages with message="Hello", stream=false
- **Verify:** Returns {items: [...], usage: {...}}, items[0].type='message'

**Test 17: Send Message (Streaming Mode)**
- **Request:** POST /conversations/:id/messages with stream=true
- **Verify:** Response Content-Type='text/event-stream', body contains SSE events

**Test 18: Send to Missing Conversation**
- **Request:** POST /conversations/nonexistent/messages
- **Verify:** 404 Not Found

**Test 19: Send Empty Message**
- **Request:** POST /conversations/:id/messages with message=""
- **Verify:** 400 Bad Request, error about empty message

**Test 20: Send Message with Tool Call**
- **Setup:** Mock model returns FunctionCall item
- **Request:** POST /conversations/:id/messages with message triggering tool
- **Verify:** Response includes function_call and function_call_output items

**Test 21: Get Message History**
- **Setup:** Create conversation, send 3 messages
- **Request:** GET /conversations/:id/messages
- **Verify:** Returns {messages: [...]}, array has 6+ items (3 user + 3 assistant)

**Test 22: Multi-Turn Conversation**
- **Execute:** Send 3 messages in sequence to same conversation
- **Verify:** Each response has context from previous messages

**Test 23: Large Message Handling**
- **Request:** Send message with 10k characters
- **Verify:** Succeeds, no truncation errors

**Test 24: Concurrent Messages to Same Conversation**
- **Execute:** Send 3 messages in parallel to same conversation
- **Verify:** All succeed (or properly queued/rejected)

**Test 25-35:** (10 more message tests covering error cases, edge cases, tool execution scenarios)

### Suite 3: Provider Parity (12 tests)

**File:** `tests/playwright/api/providers.spec.ts`

**Test 36: Responses API Works**
- **Request:** Create with api=responses, send message
- **Verify:** Response received

**Test 37: Chat API Works**
- **Request:** Create with api=chat, send message
- **Verify:** Response received

**Test 38: Messages API Works**
- **Request:** Create with api=messages, send message
- **Verify:** Response received

**Test 39: OpenRouter Works**
- **Request:** Create with provider=openai, api=chat, model=google/gemini-2.0-flash-001 (via OpenRouter)
- **Verify:** Response received

**Test 40: Provider Switching**
- **Execute:** Create conversation with openai, then create with anthropic
- **Verify:** Both work, isolated from each other

**Test 41: Thinking Mode (Responses)**
- **Request:** Create with thinking enabled, send message
- **Verify:** Response includes reasoning blocks

**Test 42: Thinking Mode (Messages)**
- **Request:** Create with thinking enabled (Messages API), send message
- **Verify:** Response includes thinking blocks

**Test 43: Temperature Variation**
- **Execute:** Send same message with temp=0.2, 0.7, 1.0
- **Verify:** Responses differ (higher temp = more variation)

**Test 44-47:** (4 more provider tests)

### Suite 4: Authentication (8 tests)

**File:** `tests/playwright/api/auth.spec.ts`

**Test 48: API Key Auth Works**
- **Request:** Create conversation with auth.method='openai-api-key'
- **Verify:** Succeeds

**Test 49: Missing Model Provider Key**
- **Setup:** Mock AuthManager returns null
- **Request:** Create conversation
- **Verify:** 400 Bad Request, error about missing provider key

**Test 50: OAuth Auth Works (Mocked)**
- **Setup:** Mock keyring with OAuth token
- **Request:** Create with auth.method='oauth-chatgpt'
- **Verify:** Succeeds, uses mocked token

**Test 51: Invalid Auth Method**
- **Request:** Create with auth.method='invalid'
- **Verify:** 400 Bad Request

**Test 52-55:** (4 more auth tests)

---

## Playwright Non-Mocked Mode Tests

**Environment:** `TEST_MODE=integration`
**Base URL:** `http://localhost:3000`
**Real APIs:** OpenAI, Anthropic, OpenRouter

### Key Scenario Tests (8 tests)

**File:** `tests/playwright/integration/smoke.spec.ts`

**Test 56: OpenAI Responses End-to-End**
- **Execute:** Create conversation (real API key), send message, verify response
- **Verify:** Real GPT-4o-mini responds

**Test 57: Anthropic Messages End-to-End**
- **Execute:** Create with Messages API, send message
- **Verify:** Real Claude responds

**Test 58: OpenRouter End-to-End**
- **Execute:** Create via OpenRouter, send message
- **Verify:** Real Gemini responds

**Test 59: Tool Execution**
- **Execute:** Send message triggering readFile tool
- **Verify:** Tool executes, result returned, model responds

**Test 60: Persistence & Resume**
- **Execute:** Create, send messages, resume, continue
- **Verify:** History preserved across resume

**Test 61: Thinking Mode (Real)**
- **Execute:** Create with thinking enabled, send complex prompt
- **Verify:** Real thinking/reasoning blocks in response

**Test 62: Temperature (Real)**
- **Execute:** Same prompt with different temperatures
- **Verify:** Outputs vary

**Test 63: Multi-Provider in One Session**
- **Execute:** Create OpenAI conversation, create Anthropic conversation, send to both
- **Verify:** Both work, isolated

---

## Mock Strategy

**Mock Model Server:**
- Implements OpenAI Responses, Chat, and Anthropic Messages endpoints
- Returns preset responses based on request
- Tracks requests for verification
- Runs on localhost:3001-3003

**Mock Search Server:**
- Implements Perplexity and Firecrawl endpoints (if Phase 4.7 tools used)
- Returns preset search results
- Runs on localhost:3004

**Mock Keyring:**
- Returns test OAuth tokens
- No real filesystem access

**Mock Filesystem:**
- Use temp directories for JSONL persistence
- Clean up after tests

---

## Verification Checklist

**Library API:**
- [ ] Can import from '@openai/codex-core'
- [ ] Factory helper works
- [ ] Types exported
- [ ] Existing mocked-service tests work with library imports
- [ ] docs/api/library-api.md complete

**REST API:**
- [ ] Server starts with Bun
- [ ] Health check works
- [ ] All endpoints respond
- [ ] docs/api/rest-api.md complete

**Playwright (mocked):**
- [ ] Conversations suite: 15 tests passing
- [ ] Messages suite: 20 tests passing
- [ ] Providers suite: 12 tests passing
- [ ] Auth suite: 8 tests passing
- [ ] Total: 55 tests, all passing in <2 minutes

**Playwright (non-mocked):**
- [ ] 8 key scenarios passing
- [ ] Real models tested
- [ ] Results logged
- [ ] Cost ~$0.05-0.10

**Quality gates:**
- [ ] TypeScript: 0 errors
- [ ] ESLint: 0 errors
- [ ] Format: clean
- [ ] Combined: All checks pass

**Code review:**
- [ ] Stage 1: API design, security, error handling
- [ ] Stage 2: Library exports clean, REST maps correctly

---

**All checks ✓ → Phase 6 test conditions complete**


---

TASKS (update source/checklist.md as you work):

# Phase 6: Library API & REST API – Task Checklist

**Status:** Not Started
**Estimated Code:** ~2,380 lines (library 450, REST API 950, Playwright 980)

---

## Setup & Planning

- [ ] Review Phases 1-5 (all functionality working)
- [ ] Read TECH-APPROACH Section 7 (Phase 6 approach)
- [ ] Read phase-6/source/design.md (implementation details)
- [ ] Install Playwright: `npm install -D @playwright/test`
- [ ] Install Fastify: `npm install fastify`
- [ ] Ensure Bun installed for runtime

---

## Library API Definition

### Exports File

- [ ] Create `src/index.ts` (main library export)
- [ ] Export ConversationManager
- [ ] Export CodexConversation
- [ ] Export createConversationManager factory
- [ ] Export types: ConversationConfig, AuthMethod, Provider, WireApi
- [ ] Export protocol types: ResponseItem, FunctionCall, UserInput
- [ ] Export utilities (optional): countTokens, parseRollout
- [ ] Verify: No internal implementation exported (Session, Codex internals stay private)

### Documentation

- [ ] Create `docs/api/library-api.md`
- [ ] Document all exported classes with signatures
- [ ] Document factory helper with usage
- [ ] Document types with field descriptions
- [ ] Add 3-5 usage examples:
  - [ ] Basic chat example
  - [ ] Multi-turn with tools example
  - [ ] Resume example
  - [ ] Provider switching example
  - [ ] Error handling example
- [ ] Document contract boundaries (what to mock for testing)

### Validation

- [ ] Create minimal test app: `examples/basic-usage.ts`
- [ ] Import library, create conversation, send message
- [ ] Verify: Example works, demonstrates library usage
- [ ] Update existing mocked-service tests to import from library
- [ ] Verify: All Phase 1-5 tests still pass with library imports

---

## REST API Implementation

### Server Setup

- [ ] Create `src/api/server.ts`
- [ ] Implement createServer(options)
- [ ] Implement startServer(port)
- [ ] Configure Fastify (logger, request ID)
- [ ] Add health check endpoint: GET /health

### Middleware

- [ ] Create `src/api/middleware/auth.ts`
  - [ ] Implement authMiddleware(expectedApiKey)
  - [ ] Extract Bearer token from Authorization header
  - [ ] Validate token matches expected
  - [ ] Return 401 if missing or invalid
  - [ ] Skip auth for /health endpoint

- [ ] Create `src/api/middleware/error.ts`
  - [ ] Implement errorMiddleware(error, req, res)
  - [ ] Map ConfigurationError → 400
  - [ ] Map AuthError → 401
  - [ ] Map ConversationNotFoundError → 404
  - [ ] Map all others → 500
  - [ ] Format: {error: {code, message, details}}

### Conversation Routes

- [ ] Create `src/api/routes/conversations.ts`
- [ ] POST /conversations (create)
  - [ ] Validate request body
  - [ ] Call manager.newConversation()
  - [ ] Return 201 with conversationId
- [ ] GET /conversations (list)
  - [ ] Call manager.listConversations()
  - [ ] Return array
- [ ] GET /conversations/:id (get)
  - [ ] Call manager.getConversation(id)
  - [ ] Return 404 if not found
  - [ ] Return metadata
- [ ] DELETE /conversations/:id (delete)
  - [ ] Call manager.removeConversation(id)
  - [ ] Return 204
- [ ] POST /conversations/:id/resume (resume)
  - [ ] Call manager.resumeConversation(id)
  - [ ] Return 404 if not found
  - [ ] Return success

### Message Routes

- [ ] Create `src/api/routes/messages.ts`
- [ ] POST /conversations/:id/messages (send)
  - [ ] Validate request (message field required)
  - [ ] Get conversation or 404
  - [ ] If stream=true:
    - [ ] Set SSE headers
    - [ ] Stream events via reply.raw.write()
    - [ ] End stream on completed event
  - [ ] If stream=false:
    - [ ] Collect all events
    - [ ] Return {items, usage}
- [ ] GET /conversations/:id/messages (history)
  - [ ] Get conversation or 404
  - [ ] Return conversation history
  - [ ] Format: {conversationId, messages: [...]}

### Config Routes

- [ ] Create `src/api/routes/config.ts`
- [ ] GET /config (get current config)
  - [ ] Return provider, api, model, auth method
- [ ] POST /config/provider (set provider)
  - [ ] Validate provider/api combo
  - [ ] Update config
  - [ ] Return success
- [ ] POST /config/auth (set auth method)
  - [ ] Validate method
  - [ ] Update config
  - [ ] Return success

### REST API Documentation

- [ ] Create `docs/api/rest-api.md`
- [ ] Document all endpoints with:
  - [ ] HTTP method and path
  - [ ] Request format (JSON schema)
  - [ ] Response format (JSON schema)
  - [ ] Status codes (success and error)
  - [ ] Example curl commands
- [ ] Document authentication (Bearer token)
- [ ] Document error response format
- [ ] Document SSE streaming format
- [ ] Add usage examples (curl, JavaScript fetch)

---

## Playwright Testing Setup

### Test Infrastructure

- [ ] Create `tests/playwright/` directory
- [ ] Create playwright.config.ts
- [ ] Configure base URL (http://localhost:3000)
- [ ] Configure test modes (mocked vs integration)
- [ ] Add npm scripts:
  - [ ] `test:playwright:mocked` - Run with mocks
  - [ ] `test:playwright:integration` - Run with real APIs
  - [ ] `test:playwright` - Run both modes

### Mock Servers

- [ ] Create `tests/playwright/mocks/model-server.ts`
  - [ ] Implement OpenAI Responses API mock
  - [ ] Implement OpenAI Chat API mock
  - [ ] Implement Anthropic Messages API mock
  - [ ] Return preset responses based on request
  - [ ] Track requests for verification

- [ ] Create `tests/playwright/mocks/search-server.ts`
  - [ ] Mock Perplexity API (if Phase 4.7 tools used)
  - [ ] Mock Firecrawl API
  - [ ] Return preset search results

- [ ] Create `tests/playwright/mocks/start-mocks.ts`
  - [ ] Start all mock servers
  - [ ] Export cleanup function
  - [ ] Use in Playwright global setup

### Test Configuration

- [ ] Create `tests/playwright/config/mocked.config.ts`
  - [ ] Mock server URLs (localhost:3001-3004)
  - [ ] Test API key
  - [ ] Mock mode flag

- [ ] Create `tests/playwright/config/integration.config.ts`
  - [ ] Real API URLs
  - [ ] Real API keys from .env
  - [ ] Integration mode flag

### Fixtures

- [ ] Create `tests/playwright/fixtures/responses.ts`
  - [ ] Preset ResponseItems for various scenarios
  - [ ] Tool call responses
  - [ ] Error responses
  - [ ] Thinking/reasoning blocks

---

## Playwright Test Implementation

### Conversations Suite

- [ ] Create `tests/playwright/api/conversations.spec.ts`
- [ ] Implement Tests 1-15 (from test-conditions.md)
- [ ] Use Playwright request API
- [ ] Verify status codes, response formats
- [ ] Test error cases

### Messages Suite

- [ ] Create `tests/playwright/api/messages.spec.ts`
- [ ] Implement Tests 16-35 (20 tests)
- [ ] Test batch and streaming modes
- [ ] Test tool execution via REST
- [ ] Test multi-turn conversations

### Providers Suite

- [ ] Create `tests/playwright/api/providers.spec.ts`
- [ ] Implement Tests 36-47 (12 tests)
- [ ] Test all three providers
- [ ] Test thinking mode
- [ ] Test temperature variation
- [ ] Verify provider parity

### Auth Suite

- [ ] Create `tests/playwright/api/auth.spec.ts`
- [ ] Implement Tests 48-55 (8 tests)
- [ ] Test all auth methods
- [ ] Test missing/invalid tokens
- [ ] Test REST API key validation

### Integration Suite (Non-Mocked)

- [ ] Create `tests/playwright/integration/smoke.spec.ts`
- [ ] Implement Tests 56-63 (8 key scenarios)
- [ ] Use real API keys
- [ ] Test with real models (cheap ones)
- [ ] Log results (latency, token usage)

---

## Quality Gates

### Code Quality

- [ ] Run: `npm run format` → no changes
- [ ] Run: `npm run lint` → 0 errors
- [ ] Run: `npx tsc --noEmit` → 0 errors

### Testing

- [ ] Run: `npm test` → all passing (mocked-service baseline + library tests)
- [ ] Run: `npm run test:playwright:mocked` → 55 tests passing in <2 min
- [ ] Run: `npm run test:playwright:integration` → 8 tests passing in ~5 min
- [ ] Verify: 0 skipped tests across all suites

### Combined Verification

- [ ] Run: `npm run format && npm run lint && npx tsc --noEmit && npm test && npm run test:playwright:mocked`
- [ ] All commands succeed
- [ ] Save output for verification

---

## Manual Verification

- [ ] Follow `manual-test-script.md`
- [ ] Test REST API with curl
- [ ] Test library with example app
- [ ] Verify Bun runtime works
- [ ] Test both streaming and batch modes

---

## Code Review

### Stage 1: Traditional Review

- [ ] API design RESTful (proper HTTP methods, status codes)
- [ ] Error handling comprehensive (all cases covered)
- [ ] Security (auth validation, input sanitization, no injection)
- [ ] Library exports minimal and clean
- [ ] REST routes thin (no business logic)
- [ ] Middleware reusable

### Stage 2: Port Validation Review

- [ ] Library exports match Rust Codex public API philosophy
- [ ] REST API maps correctly to library methods
- [ ] Playwright tests cover all integration paths
- [ ] Mock servers accurately simulate real APIs
- [ ] Non-mocked tests validate real behavior

---

## Documentation

- [ ] Update DECISIONS.md:
  - [ ] Library export choices (what/why)
  - [ ] REST API auth strategy
  - [ ] Streaming format
  - [ ] Error response format
  - [ ] Bun vs Node decision
  - [ ] Mock server approach
  - [ ] Test organization
- [ ] Verify docs/api/ complete (library-api.md, rest-api.md)
- [ ] Update checklist (mark completed)

---

## Final Verification

- [ ] All tasks completed
- [ ] All tests passing (mocked-service + Playwright mocked + Playwright integration)
- [ ] All quality gates passed
- [ ] Manual verification complete
- [ ] Code review complete (both stages)
- [ ] Documentation complete (library + REST API specs)
- [ ] Example app works
- [ ] Ready to commit and proceed to Phase 7

---

**Phase 6 complete when all items checked ✓**


---

STANDARDS:

See docs/core/dev-standards.md for complete coding standards.
See docs/core/contract-testing-tdd-philosophy.md for testing approach.

Key requirements:
- TypeScript strict mode, no any types
- ESLint 0 errors
- Prettier formatted
- Mocked-service tests at library boundaries
- Mock all external dependencies


---

EXECUTION WORKFLOW:

EXECUTION WORKFLOW:

1. Read all reference documents (project context, phase design, standards, test conditions)
2. Review checklist (understand all tasks)
3. Write mocked-service tests FIRST (TDD):
   - Create test file based on test-conditions.md
   - Implement mocks (ModelClient, Config, etc.)
   - Write tests for each functional condition
   - Run tests (should fail - nothing implemented)
4. Implement code to pass tests:
   - Create files listed in checklist
   - Follow design.md implementation specifics
   - Run tests after each component
   - Iterate until all tests green
5. Manual functional testing:
   - Follow manual-test-script.md
   - Execute each test case
   - Verify expected behavior
   - Document any issues
6. Quality verification:
   - Run: npm run format (fix formatting)
   - Run: npm run lint (fix errors)
   - Run: npx tsc --noEmit (fix type errors)
   - Run: npm test (verify all pass)
   - Run combined: npm run format && npm run lint && npx tsc --noEmit && npm test
   - All must pass before proceeding
7. Update artifacts:
   - Update checklist.md (check off completed tasks)
   - Update decisions.md (log implementation choices with rationale)
8. Final verification:
   - All checklist items checked
   - All quality gates pass
   - Manual tests successful
   - Decisions documented
9. Commit and push
10. Report completion, ready for quality verifier and code reviewer

DO NOT declare phase complete until all steps verified.


---

MANUAL VERIFICATION:

# Phase 6: Manual Test Script

**Goal:** Verify library can be imported and used, REST API works with curl/Postman, both interfaces expose same functionality

**Prerequisites:**
- Phase 5 complete (persistence working)
- Bun installed
- API keys configured

---

## Part A: Library API Testing

### Setup

**1. Create test app:**
```bash
mkdir -p /tmp/cody-test
cd /tmp/cody-test
npm init -y
npm install /path/to/codex-ts  # Link to local library
```

**2. Create test script:**
```typescript
// test-library.ts
import {createConversationManager} from '@openai/codex-core';

async function main() {
  console.log('Testing Cody library...\n');

  // Create manager
  const manager = await createConversationManager();

  // Create conversation
  const {conversation, conversationId} = await manager.newConversation({
    provider: {name: 'openai', api: 'responses', model: 'gpt-4o-mini'},
    auth: {method: 'openai-api-key'}
  });

  console.log(`✓ Created conversation: ${conversationId}\n`);

  // Send message
  await conversation.submit([{type: 'text', text: 'Say hello in one sentence'}]);
  const event = await conversation.nextEvent();

  console.log('✓ Response:', event.msg);
  console.log('\n✓ Library API works!\n');
}

main().catch(console.error);
```

### Test 1: Library Import

**Execute:**
```bash
bun test-library.ts
```

**Expected:**
- Prints "✓ Created conversation: conv_..."
- Prints response from model
- Prints "✓ Library API works!"
- No errors

**Success criteria:**
- [ ] Can import library
- [ ] Factory creates manager
- [ ] Conversation creation works
- [ ] Message sending works
- [ ] No TypeScript errors

---

## Part B: REST API Testing

### Setup

**1. Start REST API server:**
```bash
cd /path/to/codex-ts
export CODY_API_KEY=test-api-key-123
bun src/api/server.ts
```

**Expected:** Prints "✓ Cody REST API listening on http://localhost:3000"

**2. Open new terminal for testing**

### Test 2: Health Check

**Execute:**
```bash
curl http://localhost:3000/health
```

**Expected:**
```json
{"status":"ok"}
```

**Success:** [ ] Health check responds

### Test 3: Create Conversation

**Execute:**
```bash
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "openai",
    "api": "responses",
    "model": "gpt-4o-mini",
    "auth": {"method": "openai-api-key"}
  }'
```

**Expected:**
```json
{
  "conversationId": "conv_abc123",
  "created": 1699564800000,
  "provider": "openai",
  "api": "responses",
  "model": "gpt-4o-mini"
}
```

**Record conversationId for next tests**

**Success:** [ ] Conversation created via REST

### Test 4: Send Message (Batch Mode)

**Execute:**
```bash
curl -X POST http://localhost:3000/api/v1/conversations/conv_abc123/messages \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Say hello in one sentence",
    "stream": false
  }'
```

**Expected:**
```json
{
  "items": [
    {
      "type": "message",
      "role": "assistant",
      "content": [{"type": "text", "text": "Hello! ..."}]
    }
  ],
  "usage": {
    "inputTokens": 15,
    "outputTokens": 12,
    "totalTokens": 27
  }
}
```

**Success:** [ ] Message sent, response received

### Test 5: Send Message (Streaming Mode)

**Execute:**
```bash
curl -X POST http://localhost:3000/api/v1/conversations/conv_abc123/messages \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Count to 5",
    "stream": true
  }' \
  --no-buffer
```

**Expected:**
- Content-Type: text/event-stream
- Multiple `data: {...}` lines
- Events stream in real-time
- Final event has type='completed'

**Success:** [ ] Streaming works

### Test 6: List Conversations

**Execute:**
```bash
curl http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer test-api-key-123"
```

**Expected:**
```json
{
  "conversations": [
    {
      "id": "conv_abc123",
      "provider": "openai",
      "model": "gpt-4o-mini",
      "updatedAt": 1699564800000
    }
  ]
}
```

**Success:** [ ] List shows created conversation

### Test 7: Get Message History

**Execute:**
```bash
curl http://localhost:3000/api/v1/conversations/conv_abc123/messages \
  -H "Authorization: Bearer test-api-key-123"
```

**Expected:**
```json
{
  "conversationId": "conv_abc123",
  "messages": [
    {"type": "message", "role": "user", "content": [...]},
    {"type": "message", "role": "assistant", "content": [...]}
  ]
}
```

**Success:** [ ] History returned

### Test 8: Resume Conversation

**Execute:**
```bash
# Exit server (Ctrl+C), restart
bun src/api/server.ts

# Resume via API
curl -X POST http://localhost:3000/api/v1/conversations/conv_abc123/resume \
  -H "Authorization: Bearer test-api-key-123"
```

**Expected:**
```json
{
  "conversationId": "conv_abc123",
  "resumed": true
}
```

**Send message to resumed conversation:**
```bash
curl -X POST http://localhost:3000/api/v1/conversations/conv_abc123/messages \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{"message": "What did I ask you before?", "stream": false}'
```

**Expected:** Model remembers previous messages

**Success:** [ ] Resume works via REST

### Test 9: Error Cases

**Test 9a: Missing Auth Header**
```bash
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Content-Type: application/json" \
  -d '{"provider": "openai", "api": "responses", "model": "gpt-4"}'
```
**Expected:** 401 Unauthorized

**Test 9b: Invalid API Key**
```bash
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer wrong-key" \
  -H "Content-Type: application/json" \
  -d '{"provider": "openai", "api": "responses", "model": "gpt-4"}'
```
**Expected:** 401 Unauthorized

**Test 9c: Missing Conversation**
```bash
curl http://localhost:3000/api/v1/conversations/nonexistent \
  -H "Authorization: Bearer test-api-key-123"
```
**Expected:** 404 Not Found, error.code='CONVERSATION_NOT_FOUND'

**Test 9d: Invalid Request**
```bash
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{"provider": "openai"}'  # Missing api, model
```
**Expected:** 400 Bad Request, error lists missing fields

**Success:** [ ] All error cases handled correctly

### Test 10: Multi-Provider via REST

**Execute:**
```bash
# Create OpenAI conversation
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{"provider": "openai", "api": "responses", "model": "gpt-4o-mini", "auth": {"method": "openai-api-key"}}'

# Create Anthropic conversation
curl -X POST http://localhost:3000/api/v1/conversations \
  -H "Authorization: Bearer test-api-key-123" \
  -H "Content-Type: application/json" \
  -d '{"provider": "anthropic", "api": "messages", "model": "claude-3-haiku", "auth": {"method": "anthropic-api-key"}}'

# Send to both
curl -X POST http://localhost:3000/api/v1/conversations/[openai-id]/messages \
  -H "Authorization: Bearer test-api-key-123" \
  -d '{"message": "test", "stream": false}'

curl -X POST http://localhost:3000/api/v1/conversations/[anthropic-id]/messages \
  -H "Authorization: Bearer test-api-key-123" \
  -d '{"message": "test", "stream": false}'
```

**Expected:** Both work, responses from different models

**Success:** [ ] Multi-provider works via REST

---

## Part C: Playwright Automated Tests

### Test 11: Run Mocked Suite

**Execute:**
```bash
npm run test:playwright:mocked
```

**Expected:**
- ~55 tests run
- All pass
- Runtime <2 minutes
- Output shows: "55 passed"

**Success:** [ ] Mocked Playwright tests pass

### Test 12: Run Integration Suite

**Execute:**
```bash
# Ensure API keys in .env
export OPENAI_API_KEY=sk-...
export ANTHROPIC_API_KEY=sk-ant-...
export OPENROUTER_API_KEY=sk-or-...

npm run test:playwright:integration
```

**Expected:**
- ~8 tests run
- All pass (or document failures)
- Runtime ~5 minutes
- Cost ~$0.05-0.10

**Success:** [ ] Integration Playwright tests pass

---

## Success Checklist

**Library API:**
- [ ] Can import from '@openai/codex-core'
- [ ] Factory helper works
- [ ] Types exported
- [ ] Example app works
- [ ] Existing mocked-service tests work with library imports
- [ ] docs/api/library-api.md complete

**REST API:**
- [ ] Server starts with Bun
- [ ] Health check responds
- [ ] All endpoints work (create, list, send, resume)
- [ ] Streaming mode works
- [ ] Batch mode works
- [ ] Error cases handled correctly
- [ ] docs/api/rest-api.md complete

**Testing:**
- [ ] Playwright mocked: 55 tests passing
- [ ] Playwright integration: 8 tests passing
- [ ] Library validation tests passing
- [ ] All quality gates passed

**Code review:**
- [ ] Stage 1 complete (API design, security)
- [ ] Stage 2 complete (library clean, REST correct)

---

**All checks ✓ → Phase 6 functional verification complete**

**Next:** Commit changes, update project logs, assess need for Phase 7 polish


---

FINAL QUALITY CHECK:

Before declaring phase complete:

Run: npm run format && npm run lint && npx tsc --noEmit && npm test

ALL must pass. Document results.
Update checklist.md and decisions.md.
Commit and push.
Ready for verification stages.

===== END CODER PROMPT =====
